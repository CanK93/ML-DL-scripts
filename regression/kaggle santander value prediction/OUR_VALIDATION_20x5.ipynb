{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_20_cv_splits(data):\n",
    "    #stratify_classes = y\n",
    "    train = pd.read_csv(os.path.join(PATH_TO_DATA, 'input/train.csv'), usecols=['target'])\n",
    "    stratify_classes =  train.target.apply(lambda x: int(np.log10(x)))\n",
    "    splits = {}\n",
    "    for random_state in range(20):\n",
    "        column = np.zeros(data.shape[0])\n",
    "        sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=random_state)\n",
    "        for i, (_, test_index) in enumerate(sss.split(data, stratify_classes)):\n",
    "            column[test_index] = i\n",
    "\n",
    "        splits[\"split{}\".format(random_state)] = column\n",
    "\n",
    "    pd.DataFrame(splits, index=data.index).to_csv(os.path.join(PATH_TO_DATA, 'folds/cv_splits_cleandata_stat_bin_red.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # function to generate 100 folds from create_folds_from_cv_splits func\n",
    "def create_folds_from_cv_splits(in_path):\n",
    "    \n",
    "    cv_splits = pd.read_csv(os.path.join(PATH_TO_DATA, in_path))\n",
    "    folds_list = []\n",
    "    for ind, i in enumerate(cv_splits.columns[1:]):\n",
    "        folds = list(set(cv_splits[i].values))\n",
    "        folds_list.append([])\n",
    "        for m in folds:\n",
    "            val_idx = list(cv_splits[cv_splits[i]==m].index)\n",
    "            train_idx = list(set(list(cv_splits.index)) - set(val_idx))\n",
    "            folds_list[ind].append((train_idx, val_idx))\n",
    "    with open(os.path.join(PATH_TO_DATA, 'folds/custom_cv.pkl'), 'wb') as f:\n",
    "        pickle.dump(folds_list, f)\n",
    "    return folds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOAD_CV = True\n",
    "\n",
    "if LOAD_CV:\n",
    "    with open(os.path.join(PATH_TO_DATA, 'folds/custom_cv.pkl'), 'rb') as f:\n",
    "        cv_folds = pickle.load(f)\n",
    "else:\n",
    "    get_20_cv_splits(train_df)\n",
    "    cv_folds = create_folds_from_cv_splits(in_path='folds/cv_splits_cleandata_stat_bin_red.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        'max_depth': 8, # -1,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.1, # 0.6,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 44,\n",
    "        \"verbosity\" : -1,\n",
    "        'num_threads' : 4,\n",
    "        \"seed\": 44\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    model = lgb.train(params, lgtrain, 5000, \n",
    "                      valid_sets=[lgtrain, lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=150)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "    \n",
    "    pred_test_y = np.expm1(model.predict(test_X, num_iteration=model.best_iteration))\n",
    "    pred_oof_log = model.predict(val_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, pred_oof_log, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_calculations(X, test, big_cv_folds, func_name = None):\n",
    "    if not func_name:\n",
    "        return print('The function to run is not defined')\n",
    "    else:\n",
    "        y_oof_20_preds = []\n",
    "        fold_errors_20_preds =[]\n",
    "        avg_test_pred_20_preds = []\n",
    "        \n",
    "        for ind, cv_folds in enumerate(big_cv_folds):\n",
    "            print('Fitting big fold', ind+1, 'out of', len(big_cv_folds))\n",
    "            y_oof = np.zeros((y.shape[0]))\n",
    "            fold_errors =[]\n",
    "            pred_test_list = []\n",
    "            \n",
    "            for i, (train_index, val_index) in enumerate(cv_folds):\n",
    "                print('Fitting sub fold', i+1, 'out of', len(cv_folds))\n",
    "                X_train, X_val  = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "                # part to include additional functions\n",
    "                if func_name == 'lgb':\n",
    "                    pred_test_y, pred_oof_log, clf = run_lgb(X_train, y_train, X_val, y_val, test)\n",
    "                else:\n",
    "                    return print('The function to run is not correct')\n",
    "\n",
    "                y_oof[val_index] = pred_oof_log\n",
    "                curr_fe = np.sqrt(mean_squared_error(y_val, pred_oof_log))\n",
    "                print(f'Fold error {curr_fe}')\n",
    "                fold_errors.append(curr_fe)\n",
    "                pred_test_list.append(list(pred_test_y))\n",
    "\n",
    "            print('Total error', np.sqrt(mean_squared_error(y, y_oof)))\n",
    "            total_fe_std = round(np.std(fold_errors), 5)\n",
    "            print(f'Total std {total_fe_std}')\n",
    "            avg_test_pred = np.mean(pred_test_list, axis=0)\n",
    "            \n",
    "            avg_test_pred_20_preds.append(avg_test_pred)\n",
    "            fold_errors_20_preds.append(fold_errors)\n",
    "            y_oof_20_preds.append(y_oof)\n",
    "            \n",
    "        return y_oof_20_preds, avg_test_pred_20_preds, fold_errors_20_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of test predictions:', len(pred_test_list_lgb))\n",
    "avg_pred_test_list_lgb = np.mean(pred_test_list_lgb, axis=0)\n",
    "print('Length of avg test predictions:', len(avg_pred_test_list_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERRORS\n",
    "# errors = pd.DataFrame(fold_errors)\n",
    "# errors.to_csv(os.path.join(PATH_TO_DATA, 'output/tenich_20_fold_errors_1dconvnn_cv1620_std0037.pkl'), index=False, header=False)\n",
    "\n",
    "# 20x oof train preds\n",
    "with open(os.path.join(PATH_TO_DATA, 'output/tenich_20folds_train_1dconvnn_cv1561_std0021.pkl'), 'wb') as f:\n",
    "    pickle.dump(y_oof_lgb, f)\n",
    "    \n",
    "#20x test preds\n",
    "with open(os.path.join(PATH_TO_DATA, 'output/tenich_20folds_test_1dconvnn_cv1561_std0021.pkl'), 'wb') as f:\n",
    "    pickle.dump(pred_test_list_lgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../santander_data/output/tenich_20folds_test_1dconvnn_cv1561_std0021.pkl', 'rb') as fin:\n",
    "    test_preds = pickle.load(fin)\n",
    "    \n",
    "with open('../../santander_data/output/tenich_20folds_train_1dconvnn_cv1561_std0021.pkl', 'rb') as fin:\n",
    "    train_preds = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds), test_preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_preds), train_preds[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
