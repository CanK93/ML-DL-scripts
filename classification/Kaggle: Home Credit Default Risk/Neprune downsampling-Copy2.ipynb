{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import time \n",
    "import joblib\n",
    "\n",
    "FOLDS_PATH = './folds/folds.pkl'\n",
    "folds_idx = joblib.load(FOLDS_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fet = pd.read_csv('./neptune/train_features.csv.gz')\n",
    "test = pd.read_csv('./neptune/test_features.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(data, verbose = True):\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 2754.35 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dex\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Users\\dex\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 885.66 MB\n",
      "Decreased by 67.8%\n",
      "Memory usage of dataframe: 436.60 MB\n",
      "Memory usage after optimization: 138.06 MB\n",
      "Decreased by 68.4%\n"
     ]
    }
   ],
   "source": [
    "train_fet = reduce_mem_usage(train_fet)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 2043.45 MB\n",
      "Memory usage after optimization: 909.70 MB\n",
      "Decreased by 55.5%\n",
      "Memory usage of dataframe: 323.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dex\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Users\\dex\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 144.01 MB\n",
      "Decreased by 55.5%\n"
     ]
    }
   ],
   "source": [
    "train_gp = reduce_mem_usage(pd.read_csv('./input/train_df_gp.zip'))\n",
    "test_gp = reduce_mem_usage(pd.read_csv('./input/test_df_gp.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 4.69 MB\n",
      "Memory usage after optimization: 1.47 MB\n",
      "Decreased by 68.7%\n"
     ]
    }
   ],
   "source": [
    "application_train = reduce_mem_usage(pd.read_csv('./input/application_train.csv')[['SK_ID_CURR', 'TARGET']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 0.37 MB\n",
      "Memory usage after optimization: 0.19 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "application_test = reduce_mem_usage(pd.read_csv('./input/application_test.csv')[['SK_ID_CURR']])\n",
    "test = pd.concat([application_test.SK_ID_CURR, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fet = pd.concat([application_train.SK_ID_CURR, train_fet], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fet = pd.merge(train_fet, train_gp, how='left', on=['SK_ID_CURR'])\n",
    "del train_gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(test, test_gp, how='left', on=['SK_ID_CURR'])\n",
    "del test_gp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48744, 2045), (307511, 2045))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, train_fet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 2.35 MB\n",
      "Memory usage after optimization: 0.29 MB\n",
      "Decreased by 87.5%\n"
     ]
    }
   ],
   "source": [
    "application_train = reduce_mem_usage(pd.read_csv('./input/application_train.csv')[[ 'TARGET']])\n",
    "\n",
    "train_fet.drop('TARGET', axis=1, inplace=True)\n",
    "train_fet = pd.concat([application_train.TARGET, train_fet], axis=1)\n",
    "\n",
    "\n",
    "train_df = train_fet\n",
    "test_df = test\n",
    "\n",
    "features = [col for col in train_df.columns if col != 'TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_fet, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del application_train, application_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    lgbm_params = {\n",
    "            'objective': 'binary',\n",
    "            'nthread': 15,\n",
    "            'metric': 'auc',\n",
    "            #'n_estimators': 10000,\n",
    "            'learning_rate': .01,\n",
    "            'num_leaves': 35,\n",
    "            'colsample_bytree': .2,\n",
    "            'subsample': .8715623,\n",
    "            'max_depth': -1,\n",
    "            'reg_alpha': .0,\n",
    "            'reg_lambda': 100.0,\n",
    "            #'silent': -1,\n",
    "            'verbose': 100,\n",
    "            'max_bin': 277,\n",
    "            'scale_pos_weight' :1,\n",
    "            'reg_alpha': 0.0,\n",
    "            #'number_boosting_rounds': 777,\n",
    "            #'early_stopping_rounds': 100,\n",
    "            'min_child_samples': 50,\n",
    "            'subsample': 1.0,\n",
    "            'subsample_freq': 1,\n",
    "            'min_gain_to_split': 0.5 \n",
    "    }\n",
    "    return lgb.LGBMClassifier(**lgbm_params, n_estimators = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del train_x, train_y, valid_x, valid_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Tue Aug 28 23:25:07 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.793652\tvalid_1's auc: 0.798035\n",
      "Fold  1 AUC : 0.798035\n",
      "Fold 1 started at Tue Aug 28 23:26:23 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.794039\tvalid_1's auc: 0.78372\n",
      "Fold  2 AUC : 0.783720\n",
      "Fold 2 started at Tue Aug 28 23:27:39 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.794682\tvalid_1's auc: 0.79023\n",
      "Fold  3 AUC : 0.790230\n",
      "Fold 3 started at Tue Aug 28 23:28:58 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.792857\tvalid_1's auc: 0.789631\n",
      "Fold  4 AUC : 0.789631\n",
      "Fold 4 started at Tue Aug 28 23:30:13 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.792229\tvalid_1's auc: 0.787238\n",
      "Fold  5 AUC : 0.787238\n",
      "Fold 5 started at Tue Aug 28 23:31:29 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.792327\tvalid_1's auc: 0.783957\n",
      "Fold  6 AUC : 0.783957\n",
      "Fold 6 started at Tue Aug 28 23:32:45 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.792765\tvalid_1's auc: 0.791011\n",
      "Fold  7 AUC : 0.791011\n",
      "Fold 7 started at Tue Aug 28 23:34:01 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.794839\tvalid_1's auc: 0.787506\n",
      "Fold  8 AUC : 0.787506\n",
      "Fold 8 started at Tue Aug 28 23:35:23 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.794064\tvalid_1's auc: 0.797604\n",
      "Fold  9 AUC : 0.797604\n",
      "Fold 9 started at Tue Aug 28 23:36:38 2018\n",
      "Training until validation scores don't improve for 77 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.792445\tvalid_1's auc: 0.783486\n",
      "Fold 10 AUC : 0.783486\n",
      "\n",
      " 0.7892417887832485 0.005000662000601599 0.7682839842247293\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = []\n",
    "final_preds = np.zeros(test_df.shape[0])\n",
    "auc_scores = []\n",
    "    \n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds_idx):\n",
    "    print('Fold', n_fold, 'started at', time.ctime())\n",
    "    #train_x, train_y = train_df[features].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    #valid_x, valid_y = train_df[features].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "    \n",
    "    clf = get_model()\n",
    "    gc.collect()\n",
    "    clf.fit(train_df[features].iloc[train_idx], train_df['TARGET'].iloc[train_idx], \n",
    "            eval_set=[(train_df[features].iloc[train_idx], train_df['TARGET'].iloc[train_idx]), (train_df[features].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx])], \n",
    "            eval_metric='auc', verbose=100, early_stopping_rounds=77)\n",
    "    \n",
    "    oof_preds[valid_idx] = clf.predict_proba(train_df[features].iloc[valid_idx], num_iteration=clf.best_iteration_)[:, 1]\n",
    "    y_pred = clf.predict_proba(test_df[features], num_iteration=clf.best_iteration_)[:, 1]\n",
    "    final_preds += pd.Series(y_pred).rank().values\n",
    "    test_preds.append(y_pred)\n",
    "    auc_scores.append(roc_auc_score(train_df['TARGET'].iloc[valid_idx], oof_preds[valid_idx]))\n",
    "    \n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, auc_scores[-1]))\n",
    "\n",
    "print(\"\\n\", np.mean(auc_scores), np.std(auc_scores), roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "\n",
    "final_preds /= final_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./insaf_nept_gb_lgb_cv07892_std_0050.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'SK_ID_CURR': test_df['SK_ID_CURR'],\n",
    "                    'TARGET': final_preds})\n",
    "sub.to_csv('./insaf_nept_gb_lgb_cv07892_std_0050.csv', index=None)\n",
    "\n",
    "for_blending = {'train': oof_preds,\n",
    "                'test': test_preds}\n",
    "joblib.dump(for_blending, './insaf_nept_gb_lgb_cv07892_std_0050.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
