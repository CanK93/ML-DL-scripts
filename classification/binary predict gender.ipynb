{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import math \n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', delimiter= \"|\")\n",
    "test = pd.read_csv('test.csv', delimiter= \"|\")\n",
    "target = pd.read_csv('target_train.csv', delimiter= \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print train.columns, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# общая статистика\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Пo данным можно сделать вывод, что это транзакции в разных торговых точках merchant с определенной датой, суммой транзакции, mcc кодом терминала, кодом договора(term_id?) и идентификатором пользователя, и набором анонимных признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# В начале потенциально id торговой точки, пользователя и term должны оказаться лишними признаками\n",
    "# Интересно увидеть сумму транзакций по топ т.точкам, пользователям и mcc кодам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for column in train:\n",
    "    print column, \": \", len(train[column].unique())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# По колву уникальных значений получаем и фактическим значениям получаем вещественные, целочисленные и категориальные признаки\n",
    "real_features = [\"sum\", \"date\", \"f18\"]\n",
    "discrete_features = [\"merchant\", \"term_id\", \"user_id\"]\n",
    "cat_features = [\"mcc\", \"f1\", \"f2\", \"f4\",\"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\",\"f15\",\"f16\", \"f17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Имеем более менее равномерное распределение по кол-ву транзакций в разрезе т.точек на трейне \n",
    "#(взят логарифм, чтобы сгладить пик)\n",
    "print \"кол-во уникальных т.точек\", len(train.merchant.value_counts())\n",
    "np.log(train.merchant.value_counts().head(50)).plot(kind = 'bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# распределение для теста совпадает для трейна (взят логарифм, чтобы сгладить пик)\n",
    "print \"кол-во уникальных т.точек\", len(test.merchant.value_counts())\n",
    "np.log(test.merchant.value_counts().head(50)).plot(kind = 'bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Аналогично для mcc\n",
    "print \"кол-во уникальных т.точек\", len(train.mcc.value_counts())\n",
    "train.mcc.value_counts().head(50).plot(kind = 'bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Аналогично для mcc, распределения совпадают\n",
    "print \"кол-во уникальных mcc\", len(test.mcc.value_counts())\n",
    "test.mcc.value_counts().head(50).plot(kind = 'bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# гистограммы можно строить сразу по нескольким признакам, за исключением пару выбросов, имеем более мене равномерное распределение\n",
    "train[discrete_features].plot.hist(bins = 100, figsize=(20, 20))\n",
    "test[discrete_features].plot.hist(bins = 100, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# для категориальных признаков, кроме mcc.\n",
    "# Гистограммы для теста и трейна совпадают\n",
    "train[[\"f1\", \"f2\", \"f4\",\"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\",\"f15\",\"f16\", \"f17\"]].plot.hist(bins = 100, figsize=(20, 20))\n",
    "test[[\"f1\", \"f2\", \"f4\",\"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\",\"f15\",\"f16\", \"f17\"]].plot.hist(bins = 100, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Построим scatterplot для пар вещественных признаков\n",
    "import seaborn\n",
    "seaborn.pairplot(train[real_features+ [\"target\"]], hue=\"target\", diag_kind=\"kde\")\n",
    "\n",
    "# по результатом видно, что таргет 1 чаще при более крупных сумме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# аналогично для категориальных признаков, для первых 10к значений \n",
    "seaborn.pairplot(train[cat_features + [\"target\"]].head(10000), hue=\"target\", diag_kind=\"kde\")\n",
    "# признаков много, но можно выявить интересные закономерности. Оставим для более глубого анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# аналогично для дискретных признаков, для первых 10к значений \n",
    "seaborn.pairplot(train[discrete_features + [\"target\"]].head(10000), hue=\"target\", diag_kind=\"kde\")\n",
    "# эти три признака на первый взгляд не влияют на отклик, генерацию признаков отложим до первого безлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# построим матрицу корреляций не категориальных признаков\n",
    "seaborn.heatmap(train[discrete_features+real_features].corr(), square=True)\n",
    "\n",
    "#значимой коррелации, кроме как т.точки и term_id (договор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.date.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# поиграемсяс датой, добавим день месяц и тд\n",
    "train = pd.read_csv('train.csv', delimiter= \"|\")\n",
    "test = pd.read_csv('test.csv', delimiter= \"|\")\n",
    "target = pd.read_csv('target_train.csv', delimiter= \"|\")\n",
    "\n",
    "def fix_date_time(df):\n",
    "    def extract_field(_df, start, stop):\n",
    "        return _df['date'].map(lambda dt: int(dt[start:stop]))\n",
    "    df['Year'] = extract_field(df,0,4)\n",
    "    df['Month'] = extract_field(df,5,7)\n",
    "    df['Day'] = extract_field(df,8,10)\n",
    "    df['Hour'] = extract_field(df,11,13)\n",
    "    df['Minute'] = extract_field(df,14,16)\n",
    "    \n",
    "    return df.drop(['date'], axis = 1)\n",
    "\n",
    "train = fix_date_time(train)\n",
    "test = fix_date_time(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print train.Year.unique(), test.Year.unique()\n",
    "# диапозоны дат у данных пересекающиеся, так что "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_fit, X_eval, y_fit, y_eval= train_test_split(\n",
    "    train, target, test_size=0.20, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#обучим первую модель. Логистическую регрессию, поварьируем регуляризацию\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import grid_search\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "CVscores = cross_validation.cross_val_score(lr, X_fit, y_fit.target, scoring='roc_auc', cv=5)\n",
    "\n",
    "#поварьируем регуляризацию\n",
    "Cs = 10**np.linspace(-4, 4, num=10)\n",
    "grid = {'C': Cs}\n",
    "gridsearch = grid_search.GridSearchCV(lr, grid, scoring='roc_auc', cv=5)\n",
    "gridsearch.fit(X_fit, y_fit.target)\n",
    "gridscores = [-x.mean_validation_score for x in gridsearch.grid_scores_]\n",
    "\n",
    "C = Cs[np.argmin(gridscores)]\n",
    "\n",
    "# обучим модель с полученными параметрами\n",
    "lrCV = LogisticRegression(C=C)\n",
    "lrCV.fit(X_fit, y_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auc_train = roc_auc_score(y_fit.target, lrCV.predict(X_fit))\n",
    "auc_val = roc_auc_score(y_eval.target, lrCV.predict(X_eval))\n",
    "\n",
    "print 'auc_train: ', auc_train\n",
    "print 'auc_val: ', auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# результаты получиcь достаточно плохие, если в таргете среднее значение результатов 0,47, то тут 0,06  - модель сильно переобучилась в сторону 0\n",
    "print np.mean(lrCV.predict(X_fit)), target.mean(), np.mean(y_fit.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Применим xgboost, он должен показать хорошие первоначальные результаты за счет того что \n",
    "# отлично борется c переобучением\n",
    "# Разделим данные на обучающую, валидационную и тестовую выборку. Данные достаточно много, это имеет смысл сделать \n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(missing=np.nan, max_depth=3, \n",
    "                        n_estimators=750, learning_rate=0.01, gamma =0.3, min_child_weight = 3,\n",
    "                        subsample=0.9, colsample_bytree=0.8, seed=2000,objective= 'binary:logistic')\n",
    "\n",
    "clf.fit(X_fit, y_fit, early_stopping_rounds=40,  eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auc_train = roc_auc_score(y_fit.target, clf.predict(X_fit))\n",
    "auc_val = roc_auc_score(y_eval.target, clf.predict(X_eval))\n",
    "\n",
    "print 'auc_train: ', auc_train\n",
    "print 'auc_val: ', auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print np.mean(clf.predict(X_fit)), target.mean(), np.mean(y_fit.target)\n",
    "# значения стало лучше AUC чуть меньше 0,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# расмотрим какие признаки модель посчитала важными\n",
    "def get_xgb_imp(xgb, feat_names):\n",
    "    from numpy import array\n",
    "    imp_vals = xgb.booster().get_fscore()\n",
    "    imp_dict = {feat_names[i]:float(imp_vals.get('f'+str(i),0.)) for i in range(len(feat_names))}\n",
    "    total = array(imp_dict.values()).sum()\n",
    "    return {k:v/total for k,v in imp_dict.items()}\n",
    "\n",
    "get_xgb_imp(clf,X_fit.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# необычно, юзер id - оказался сильно значимым признаком.\n",
    "# огорчает, что неизвестно на момент решения задачи что именно классиф.\n",
    "train = train.drop(['f14', 'f15'],axis=1)\n",
    "test = test.drop(['f14', 'f15'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# добавим частоту транзакций к mcc коду\n",
    "\n",
    "mcc_con = pd.concat([test['mcc'], train['mcc']])\n",
    "values = dict(mcc_con.value_counts())\n",
    "\n",
    "train['_mcc_freq'] = train['mcc'].map(values)\n",
    "test['_mcc_freq'] = test['mcc'].map(values)\n",
    "\n",
    "train['_mcc_freq'] = train['_mcc_freq'].fillna(-1)\n",
    "test['_mcc_freq'] = test['_mcc_freq'].fillna(-1)\n",
    "\n",
    "print train.head()\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# обучим модель еще раз\n",
    "X_fit, X_eval, y_fit, y_eval= train_test_split(\n",
    "    train, target, test_size=0.20, random_state=1\n",
    ")\n",
    "\n",
    "clf = xgb.XGBClassifier(missing=np.nan, max_depth=3, \n",
    "                        n_estimators=750, learning_rate=0.01, gamma =0.3, min_child_weight = 3,\n",
    "                        subsample=0.9, colsample_bytree=0.8, seed=2000,objective= 'binary:logistic')\n",
    "\n",
    "clf.fit(X_fit, y_fit, early_stopping_rounds=40,  eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "auc_train = roc_auc_score(y_fit.target, clf.predict(X_fit))\n",
    "auc_val = roc_auc_score(y_eval.target, clf.predict(X_eval))\n",
    "\n",
    "print 'auc_train: ', auc_train\n",
    "print 'auc_val: ', auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# результаты несколько улучшились\n",
    "get_xgb_imp(clf,X_fit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# новый признак не привнес нового в модель, дропнем его, но попробуем заменить частотами три айдишника, кроме mcc\n",
    "# при этом сами id дропнуть\n",
    "\n",
    "\n",
    "term_con = pd.concat([test['term_id'], train['term_id']])\n",
    "values = dict(term_con.value_counts())\n",
    "\n",
    "train['_term_freq'] = train['term_id'].map(values)\n",
    "test['_term_freq'] = test['term_id'].map(values)\n",
    "\n",
    "\n",
    "mer_con = pd.concat([test['merchant'], train['merchant']])\n",
    "values = dict(mer_con.value_counts())\n",
    "\n",
    "train['_merchant_freq'] = train['merchant'].map(values)\n",
    "test['_merchant_freq'] = test['merchant'].map(values)\n",
    "\n",
    "user_con = pd.concat([test['user_id'], train['user_id']])\n",
    "values = dict(mer_con.value_counts())\n",
    "\n",
    "train['_user_freq'] = train['merchant'].map(values)\n",
    "test['_user_freq'] = test['merchant'].map(values)\n",
    "\n",
    "\n",
    "#дропнем так же незначимые признаки\n",
    "train = train.drop(['Minute', 'Year', 'f11', 'f12', 'f13', 'f16', 'f17', 'f7', 'f8'],axis=1) \n",
    "test = test.drop(['Minute', 'Year', 'f11', 'f12', 'f13', 'f16', 'f17', 'f7', 'f8'],axis=1)\n",
    "\n",
    "train = train.drop(['merchant', 'user_id', 'term_id'],axis=1)\n",
    "test = test.drop(['merchant', 'term_id', 'user_id'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_fit, X_eval, y_fit, y_eval= train_test_split(\n",
    "    train, target, test_size=0.20, random_state=1\n",
    ")\n",
    "clf = xgb.XGBClassifier(missing=np.nan, max_depth=3, \n",
    "                        n_estimators=1300, learning_rate=0.02, gamma =0.3, min_child_weight = 3,\n",
    "                        subsample=0.9, colsample_bytree=0.8, seed=2000,objective= 'binary:logistic')\n",
    "\n",
    "clf.fit(X_fit, y_fit, early_stopping_rounds=50,  eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "auc_train = roc_auc_score(y_fit.target, clf.predict(X_fit))\n",
    "auc_val = roc_auc_score(y_eval.target, clf.predict(X_eval))\n",
    "\n",
    "print 'auc_train: ', auc_train\n",
    "print 'auc_val: ', auc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_target = clf.predict(test)\n",
    "submission = pd.DataFrame(test_target)\n",
    "submission.to_csv(\"test_target.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
