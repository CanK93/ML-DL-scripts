{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake news.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "pJ5tsVGv4iwj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**WSDM - Fake News Classification**\n",
        "\n",
        "https://www.kaggle.com/c/fake-news-pair-classification-challenge"
      ]
    },
    {
      "metadata": {
        "id": "h_yHc7isYCFz",
        "colab_type": "code",
        "outputId": "f426e72c-37e7-4d1a-8288-dac383a8a645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports here\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "import torch,torchvision\n",
        "#!pip install -I pillow\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#!pip install Pillow==4.0.0\n",
        "#!pip install PIL\n",
        "#!pip install image\n",
        "#import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import pickle\n",
        "import nltk\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "data_dir = '/drive/My Drive/Study/fakenews/'\n",
        "isPreprocess = True\n",
        "from google.colab import drive\n",
        "drive.mount('/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x62192000 @  0x7f3f26ee12a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 4.0MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SHkCc1oF-R4C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MV419bPWZa9_",
        "colab_type": "code",
        "outputId": "743c7564-9a28-4951-c828-e8cb5e957072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\".\"))\n",
        "print(os.listdir(\"/drive/My Drive\"))\n",
        "#os.chdir(\"drive/Colab/\")\n",
        "#print(os.listdir(\".\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'sample_data']\n",
            "['IMG_1806.MOV', 'Teradata - работа', 'поиск вакансий', 'Проекты по кодингу', 'Дипломы, эссе, презентации', 'Study', 'Google Фото', 'python', 'Манифест неоэкзистенциализма.gdoc', 'финансы.xlsx.gsheet', 'финансы 23.02.2018.xlsx', 'Colab Notebooks', 'vpn.zip', 'Kaggle: homecredit.gsheet', 'temp', 'TGS_SALT-master.zip', 'квартиры.gsheet', '2kzn.pdf', '2msk.pdf', 'финансы 23.02.2018.xlsx.gsheet', 'Мебель.gsheet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dhNlAJPh39m2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "Eljat_kG4Did",
        "colab_type": "code",
        "outputId": "fc190a17-d7b4-4df1-cdce-e910fe9ad52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#nltk.download('stopwords')\n",
        "stopwords_en = stopwords.words('english')\n",
        "stopwords_en.remove(\"not\")\n",
        "stopwords_en.remove(\"no\")\n",
        "stopwords_en.remove(\"nor\")\n",
        "'''\n",
        "stopwords_en = ['the', 'a' 'an']\n",
        "def make_new_data(df):\n",
        "\n",
        "    title1_en = list(df[\"title1_en\"])\n",
        "    title2_en = list(df[\"title2_en\"])\n",
        "    title1_zh = list(df[\"title1_zh\"])\n",
        "    title2_zh = list(df[\"title2_zh\"])\n",
        "    labels = list(df[\"label\"])\n",
        "    id1_train = list(df[\"tid1\"])\n",
        "    id2_train = list(df[\"tid2\"])\n",
        "\n",
        "\n",
        "    # id-text dictionary\n",
        "    id_to_text_en = defaultdict(list)\n",
        "    id_to_text_zh = defaultdict(list)\n",
        "    for idx, id1 in enumerate(id1_train):\n",
        "        #if not id1 in id_to_text_en.keys():\n",
        "        id_to_text_en[id1] = title1_en[idx]\n",
        "        id_to_text_zh[id1] = title1_zh[idx]\n",
        "\n",
        "    for idx, id2 in enumerate(id2_train):\n",
        "        #if not id2 in id_to_text_en.keys():\n",
        "        id_to_text_en[id2] = title2_en[idx]\n",
        "        id_to_text_zh[id2] = title2_zh[idx]\n",
        "\n",
        "\n",
        "    # key : id,\n",
        "    # value : id of agreed text or diagreed text.\n",
        "    agree_dic = defaultdict(list)\n",
        "    disagree_dic = defaultdict(list)\n",
        "    \n",
        "    given_dic = defaultdict(list)\n",
        "    bidirection_dic = defaultdict(list)\n",
        "\n",
        "    fixed_dic = defaultdict(list)\n",
        "\n",
        "    for idx, id1 in enumerate(id1_train):\n",
        "        label = labels[idx]\n",
        "        id2 = id2_train[idx]\n",
        "        given_dic[id1].append((id2, label))\n",
        "\n",
        "    # for idx, id1 in enumerate(id1_train):\n",
        "    #     label = labels[idx]\n",
        "    #     id2 = id2_train[idx]\n",
        "    #     given_dic[id1].append((id2, label))\n",
        "    \n",
        "    for idx, id1 in enumerate(id1_train):\n",
        "        label = labels[idx]\n",
        "        id2 = id2_train[idx]\n",
        "\n",
        "        if not len(fixed_dic[id1]) == 0:\n",
        "            already_given_id = np.array(fixed_dic[id1])[:,0]\n",
        "            already_given_label = np.array(fixed_dic[id1])[:,1]\n",
        "            if not id2 in already_given_id:\n",
        "                fixed_dic[id1].append([id2, label])\n",
        "            else:\n",
        "                id2_idx = list(already_given_id).index(id2)\n",
        "                already_given = already_given_label[id2_idx]\n",
        "                if not label == already_given:\n",
        "                    #print(id1, id2, already_given, label)\n",
        "                    if label == 0:\n",
        "                        pass\n",
        "                    elif label == 1 and already_given == 0:\n",
        "                        true_label = 1                        \n",
        "                        fixed_dic[id1][id2_idx][1] = true_label\n",
        "                    elif label == 2 or already_given == 2:\n",
        "                        true_label = 2\n",
        "                        fixed_dic[id1][id2_idx][1] = true_label\n",
        "                    #print(id1, given_dic[id1][id2_idx])\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        else:\n",
        "            #最初に登録するとき\n",
        "            fixed_dic[id1].append([id2, label])\n",
        "\n",
        "        if not len(fixed_dic[id2]) == 0:\n",
        "            already_given_id = np.array(fixed_dic[id2])[:,0]\n",
        "            already_given_label = np.array(fixed_dic[id2])[:,1]\n",
        "            if not id1 in already_given_id:\n",
        "                fixed_dic[id2].append([id1, label])\n",
        "            else:\n",
        "                id1_idx = list(already_given_id).index(id1)\n",
        "                already_given = already_given_label[id1_idx]\n",
        "                if not label == already_given:\n",
        "                    if label == 0:\n",
        "                        pass\n",
        "                    elif label == 1 and already_given == 0:\n",
        "                        true_label = 1\n",
        "                        fixed_dic[id2][id1_idx][1] = true_label\n",
        "                    elif label == 2 or already_given == 2:\n",
        "                        true_label = 2\n",
        "                        fixed_dic[id2][id1_idx][1] = true_label\n",
        "\n",
        "\n",
        "        else:\n",
        "            fixed_dic[id2].append([id1, label])\n",
        "    print(\"agree dic:{}, disagree dic:{}\".format(len(agree_dic), len(disagree_dic)))\n",
        "\n",
        "    fixed_dic_cleaned = copy.deepcopy(fixed_dic)\n",
        "    print(\"deleting dublicates\")\n",
        "    for id_, id_label_list in tqdm(fixed_dic_cleaned.items()):\n",
        "        #print(id_label_list)\n",
        "        if len(id_label_list) == 0:\n",
        "            continue\n",
        "        id_list = np.array(id_label_list)[:,0]\n",
        "        for eachid in id_list:\n",
        "            id_label_list2 = fixed_dic_cleaned[eachid]\n",
        "            if len(id_label_list2) == 0:\n",
        "                continue\n",
        "\n",
        "            id_list2 = list(np.array(id_label_list2)[:,0])\n",
        "            if id_ in id_list2:\n",
        "                idx = list(id_list2).index(id_)\n",
        "                id_label_list2.pop(idx)\n",
        "\n",
        "    for id1, id_label_list in fixed_dic.items():\n",
        "        if len(id_label_list) == 0:\n",
        "            continue\n",
        "        id_list = np.array(id_label_list)[:,0]\n",
        "        label_list = np.array(id_label_list)[:,1]\n",
        "        for id2, label in zip(id_list, label_list):\n",
        "\n",
        "            if label == 1:\n",
        "                agree_dic[id1].append(id2)\n",
        "            elif label == 2:\n",
        "                disagree_dic[id1].append(id2)\n",
        "\n",
        "    new_data = []\n",
        "    given_label_agree = []\n",
        "    given_label_dis = []\n",
        "\n",
        "\n",
        "    for id1, id_label_list in fixed_dic_cleaned.items():\n",
        "        if len(id_label_list) == 0:\n",
        "            continue\n",
        "        id2_list = np.array(id_label_list)[:,0]\n",
        "        label_list = np.array(id_label_list)[:,1]\n",
        "        for id2, label in zip(id2_list, label_list):\n",
        "            new_data.append((id_to_text_en[id1], id_to_text_en[id2], id_to_text_zh[id1], id_to_text_zh[id2], label))\n",
        "\n",
        "\n",
        "    print(\"fixed data length:{}, original:{}\".format(len(new_data), len(id1_train)))\n",
        "\n",
        "\n",
        "    forecast_dic = defaultdict(list)\n",
        "\n",
        "    for id_, agree_ids in agree_dic.items():\n",
        "        disagree_ids = disagree_dic[id_]\n",
        "\n",
        "        for agree_id in agree_ids:\n",
        "            given_ids_labels= fixed_dic[agree_id]\n",
        "            if len(given_ids_labels) == 0:\n",
        "                continue\n",
        "            given_ids = np.array(given_ids_labels)[:, 0]\n",
        "            given_labels = np.array(given_ids_labels)[:, 1]\n",
        "            assert given_ids.shape == given_labels.shape\n",
        "\n",
        "            # new 'disagree data'\n",
        "            for disagree_id in disagree_ids:\n",
        "                if disagree_id in given_ids:\n",
        "                    # When labels are already given\n",
        "                    idx = list(given_ids).index(disagree_id)\n",
        "                    label = given_labels[idx]\n",
        "                    given_label_dis.append(label)\n",
        "                    pass\n",
        "                else:\n",
        "                    # hen the label is not given explicitly\n",
        "                    forecast_dic[agree_id].append((disagree_id, 2))\n",
        "                    forecast_dic[disagree_id].append((agree_id, 2))\n",
        "                    new_data.append((id_to_text_en[agree_id], id_to_text_en[disagree_id], id_to_text_zh[agree_id], id_to_text_zh[disagree_id], 2))\n",
        "\n",
        "            # new 'agree data'\n",
        "            for agree_id2 in agree_ids:\n",
        "                if agree_id == agree_id2:\n",
        "                    continue\n",
        "                else:\n",
        "                    if agree_id2 in given_ids:\n",
        "                        # when labels are already given\n",
        "                        idx = list(given_ids).index(agree_id2)\n",
        "                        label = given_labels[idx]\n",
        "                        given_label_agree.append(label)\n",
        "                        pass\n",
        "                    else:\n",
        "                        pass\n",
        "                        # when the label is not given explicitly.\n",
        "                        forecast_dic[agree_id].append((agree_id2, 1))\n",
        "                        forecast_dic[agree_id2].append((agree_id, 1))\n",
        "\n",
        "                        # new_data.append((id_to_text_en[agree_id], id_to_text_en[agree_id2], id_to_text_zh[agree_id], id_to_text_zh[agree_id2], 1))\n",
        "\n",
        "#     c = Counter(given_label_agree)\n",
        "#     print(\"given_label_agree\", c)\n",
        "#     c = Counter(given_label_dis)\n",
        "#     print(\"given_label_disagree\", c)\n",
        "    print(\"final data length:\",len(new_data))\n",
        "    with open(data_dir + 'save/fixed_dic.pickle', mode='wb') as f:\n",
        "        pickle.dump(fixed_dic, f)\n",
        "    with open(data_dir + 'save/given_dic.pickle', mode='wb') as f:\n",
        "        pickle.dump(given_dic, f)\n",
        "    with open(data_dir + 'save/forecast_dic.pickle', mode='wb') as f:\n",
        "        pickle.dump(forecast_dic, f)\n",
        "\n",
        "    return new_data, given_dic, fixed_dic, forecast_dic \n",
        "def preprocess_():\n",
        "\n",
        "    train_df = pd.read_csv(data_dir + \"train.csv\")\n",
        "    test_df = pd.read_csv(data_dir + \"test.csv\")\n",
        "    sub = pd.read_csv(data_dir + \"sample_submission.csv\")\n",
        "\n",
        "    def english_clean_series(series):\n",
        "        # Uppercase letters ---> lowercase letters\n",
        "        series = series.str.lower()\n",
        "\n",
        "        def clean_seq(seq):\n",
        "            seq = seq.replace(\"it's\", \"it is\")\n",
        "            seq = seq.replace(\"he's\", \"he is\")\n",
        "            seq = seq.replace(\"she's\", \"she is\")\n",
        "            seq = seq.replace(\"you're\", \"you are\")\n",
        "            seq = seq.replace(\"we're\", \"we are\")\n",
        "            seq = seq.replace(\"they're\", \"they are\")\n",
        "            seq = seq.replace(\"i'm\", \"i am\")\n",
        "            seq = seq.replace(\"don't\", \"do not\")\n",
        "            seq = seq.replace(\"does't\", \"does not\")\n",
        "            seq = seq.replace(\"didn't\", \"did not\")\n",
        "            seq = seq.replace(\"aren't\", \"are not\")\n",
        "            seq = seq.replace(\"weren't\", \"were not\")\n",
        "            seq = seq.replace(\"isn't\", \"is not\")\n",
        "            seq = seq.replace(\"wasn't\", \"was not\")\n",
        "            seq = seq.replace(\"haven't\", \"have not\")\n",
        "            seq = seq.replace(\"hasn't\", \"has not\")\n",
        "            seq = seq.replace(\"can't\", \"can not\")\n",
        "            seq = seq.replace(\"cannot\", \"can not\")\n",
        "\n",
        "            seq = seq.replace(\"shouldn't\", \"should not\")\n",
        "            seq = seq.replace(\"wouldn't\", \"would not\")\n",
        "            seq = seq.replace(\"couldn't\", \"could not\")\n",
        "            seq = seq.replace(\"mightn't\", \"might not\")\n",
        "            seq = seq.replace(\"mustn't\", \"must not\")\n",
        "            seq = seq.replace(\"needn't\", \"need not\")\n",
        "            seq = seq.replace(\"won't\", \"will not\")\n",
        "\n",
        "            seq = seq.replace(\"'s\", \"\")\n",
        "            seq = seq.replace(\"\\n\", \"\")\n",
        "            seq = seq.replace(\"[\", \"\")\n",
        "            seq = seq.replace(\"]\", \"\")\n",
        "            seq = seq.replace(\" the \", \" \")\n",
        "            seq = seq.replace(\" a \", \" \")\n",
        "            seq = seq.replace(\" an \", \" \")\n",
        "\n",
        "\n",
        "            seq = seq.replace(\"< i >\", \"\")\n",
        "            seq = seq.replace(\"< / i >\", \"\")\n",
        "\n",
        "            seq = re.sub(r'[,.\"''“”。、#()→⇒←↓↑:;_㊙️【《》=|/+<>]+', '', seq)\n",
        "            seq = seq.replace(r'-', ' - ')\n",
        "            seq = seq.replace(r'!', ' ! ')\n",
        "            seq = seq.replace(r'?', ' ? ') \n",
        "            seq = seq.replace(r'?', ' ? ')\n",
        "            seq = seq.replace(r'！', ' ! ')\n",
        "            seq = seq.replace(r'？', ' ? ')\n",
        "            seq = re.sub(r'[$]+', '$ ', seq)\n",
        "            seq = re.sub(r'[0-9]+', '<NUM>', seq)\n",
        "\n",
        "            seq_split = seq.split(\" \")\n",
        "\n",
        "            new_seq = \"\"\n",
        "            for word in seq_split:\n",
        "                if not word in stopwords_en:\n",
        "                    new_seq += word\n",
        "                    new_seq += \" \"\n",
        "            return new_seq\n",
        "        '''\n",
        "            with open('save/top_words.pickle', mode='rb') as f:\n",
        "                top_words = pickle.load(f)\n",
        "\n",
        "            # Leave frequent top 20000 words. Do we need them???\n",
        "            seq = new_seq\n",
        "            seq_split = seq.split(\" \")\n",
        "            new_seq = \"\"\n",
        "            for word in seq_split:\n",
        "                if word in top_words:\n",
        "                    new_seq += word\n",
        "                    new_seq += \" \"\n",
        "\n",
        "            return new_seq\n",
        "        series = series.apply(clean_seq)\n",
        "        '''\n",
        " \n",
        "        return series.apply(clean_seq)\n",
        "\n",
        "    def chinese_clean_series(series):\n",
        "        def clean_seq(seq):\n",
        "            seq = str(seq)\n",
        "            seq = seq.replace(\"< i >\", \"\")\n",
        "            seq = seq.replace(\"< / i >\", \"\")\n",
        "            seq = seq.replace(\"\\n\", \"\")\n",
        "            seq = re.sub(r'[,.\"''“”。、#()→⇒←↓↑:;_㊙️【《》=|/<>]+', '', seq)\n",
        "            #seq = re.sub(r'[!！？?-]+', ' ', seq)\n",
        "            seq = seq.replace(r'-', ' - ')\n",
        "            seq = seq.replace(r'!', ' ! ')\n",
        "            seq = seq.replace(r'?', ' ? ') \n",
        "            seq = seq.replace(r'?', ' ? ')\n",
        "            seq = seq.replace(r'！', ' ! ')\n",
        "            seq = seq.replace(r'？', ' ? ')\n",
        "            seq = re.sub(r'[$]+', '$ ', seq)\n",
        "            seq = re.sub(r'万', '00', seq)            \n",
        "            seq = re.sub(r'[0-9]+', '<NUM>', seq)\n",
        "\n",
        "            return seq\n",
        "\n",
        "        series = series.apply(clean_seq)\n",
        "        return series\n",
        "\n",
        "    train_df[\"title1_en\"] = english_clean_series(train_df[\"title1_en\"])\n",
        "    train_df[\"title2_en\"] = english_clean_series(train_df[\"title2_en\"])\n",
        "    train_df[\"title1_zh\"] =  chinese_clean_series(train_df[\"title1_zh\"])\n",
        "    train_df[\"title2_zh\"] =  chinese_clean_series(train_df[\"title2_zh\"])\n",
        "\n",
        "    test_df[\"title1_en\"] = english_clean_series(test_df[\"title1_en\"])\n",
        "    test_df[\"title2_en\"] = english_clean_series(test_df[\"title2_en\"])\n",
        "    test_df[\"title1_zh\"] =  chinese_clean_series(test_df[\"title1_zh\"])\n",
        "    test_df[\"title2_zh\"] =  chinese_clean_series(test_df[\"title2_zh\"])\n",
        "\n",
        "    train_df.replace('unrelated', 0, inplace=True)\n",
        "    train_df.replace('agreed', 1, inplace=True)\n",
        "    train_df.replace('disagreed', 2, inplace=True)\n",
        "\n",
        "    y = list(train_df[\"label\"])\n",
        "\n",
        "\n",
        "    #Create a word dictionary\n",
        "\n",
        "    train_t1_en = train_df[\"title1_en\"]\n",
        "    train_t2_en = train_df[\"title2_en\"]\n",
        "\n",
        "    test_t1_en = test_df[\"title1_en\"]\n",
        "    test_t2_en = test_df[\"title2_en\"]\n",
        "\n",
        "    train_t1_zh = train_df[\"title1_zh\"]\n",
        "    train_t2_zh = train_df[\"title2_zh\"]\n",
        "    test_t1_zh = test_df[\"title1_zh\"]\n",
        "    test_t2_zh = test_df[\"title2_zh\"]\n",
        "\n",
        "    label = train_df[\"label\"]\n",
        "    print(train_t1_en.head())\n",
        "    word_to_ix_en = {}\n",
        "    for title1, title2 in zip(tqdm(train_t1_en), train_t2_en):         \n",
        "        for word in title1.split():\n",
        "            if word not in word_to_ix_en.keys():\n",
        "                word_to_ix_en[word] = len(word_to_ix_en)+1\n",
        "        for word in title2.split():\n",
        "            if word not in word_to_ix_en.keys():\n",
        "                word_to_ix_en[word] = len(word_to_ix_en)+1\n",
        "\n",
        "    for title1, title2 in zip(tqdm(test_t1_en), test_t2_en):\n",
        "        for word in title1.split():\n",
        "            if word not in word_to_ix_en.keys():\n",
        "                word_to_ix_en[word] = len(word_to_ix_en)+1\n",
        "        for word in title2.split():\n",
        "            if word not in word_to_ix_en.keys():\n",
        "                word_to_ix_en[word] = len(word_to_ix_en)+1\n",
        "\n",
        "\n",
        "    #Chinese\n",
        "    word_to_ix_zh = {}\n",
        "    for title1, title2 in zip(tqdm(train_t1_zh), train_t2_zh):\n",
        "        for word in title1:\n",
        "            if word not in word_to_ix_zh.keys():\n",
        "                word_to_ix_zh[word] = len(word_to_ix_zh)+1\n",
        "        for word in title2:\n",
        "            if word not in word_to_ix_zh.keys():\n",
        "                word_to_ix_zh[word] = len(word_to_ix_zh)+1\n",
        "\n",
        "    for title1, title2 in zip(tqdm(test_t1_zh), test_t2_zh):\n",
        "        for word in title1:\n",
        "            if word not in word_to_ix_zh.keys():\n",
        "                word_to_ix_zh[word] = len(word_to_ix_zh)+1\n",
        "        for word in title2:\n",
        "            if word not in word_to_ix_zh.keys():\n",
        "                word_to_ix_zh[word] = len(word_to_ix_zh)+1\n",
        "\n",
        "    print(\"the number of english words:{}, chinese words:{}\".format(len(word_to_ix_en), len(word_to_ix_zh)))\n",
        "\n",
        "    with open(data_dir + 'save/word_to_ix_en.pickle', mode='wb') as f:\n",
        "        pickle.dump(word_to_ix_en, f)\n",
        "    with open(data_dir + 'save/word_to_ix_zh.pickle', mode='wb') as f:\n",
        "        pickle.dump(word_to_ix_zh, f)\n",
        "    with open(data_dir + 'save/train_df.pickle', mode='wb') as f:\n",
        "        pickle.dump(train_df, f)\n",
        "    with open(data_dir + 'save/test_df.pickle', mode='wb') as f:\n",
        "        pickle.dump(test_df, f)\n",
        "\n",
        "    print(\"cleaned df, word to ix saved.\")\n",
        "\n",
        "\n",
        "    # The agree articles to A may be in a disagreeous relationship with disagree articles in A?\n",
        "\n",
        "    # with open('save/word_to_ix_en.pickle', mode='rb') as f:\n",
        "    #      word_to_ix_en = pickle.load(f)\n",
        "    # with open('save/word_to_ix_zh.pickle', mode='rb') as f:\n",
        "    #      word_to_ix_zh = pickle.load(f)\n",
        "    # with open('save/train_df.pickle', mode='rb') as f:\n",
        "    #      train_df = pickle.load(f)\n",
        "    # with open('save/test_df.pickle', mode='rb') as f:\n",
        "    #      test_df = pickle.load(f)\n",
        "\n",
        "    #\n",
        "    # title1_en = list(train_df[\"title1_en\"])\n",
        "    # title2_en = list(train_df[\"title2_en\"])\n",
        "    # title1_zh = list(train_df[\"title1_zh\"])\n",
        "    # title2_zh = list(train_df[\"title2_zh\"])\n",
        "    # labels = list(train_df[\"label\"])\n",
        "    #\n",
        "    # id1 = list(train_df[\"tid1\"])\n",
        "    # id2 = list(train_df[\"tid2\"])\n",
        "    #\n",
        "    # #id1_train, id1_val, train1_en, val1_en, train1_zh, val1_zh, id2_train, id2_val, train2_en, val2_en,train2_zh, val2_zh, y_train, y_val = train_test_split(id1, title1_en, title1_zh, id2, title2_en, title2_zh, labels, test_size=0.2, random_state=0)\n",
        "    # training_df, val_df = train_test_split(train_df, test_size=0.2, random_state=0)\n",
        "    #\n",
        "    #\n",
        "    # #new_data, _ = make_new_data(id1_train, id2_train, train1_en, train2_en, y_train)\n",
        "    # new_data, _, _ = make_new_data(training_df)\n",
        "    #\n",
        "    # #print(len(new_data_en))\n",
        "    #\n",
        "    # train1_en, train2_en = [],[]\n",
        "    # train1_zh, train2_zh = [],[]\n",
        "    # y_train = []\n",
        "    # for text1_en, text2_en, text1_zh, text2_zh,label in new_data:\n",
        "    #         train1_en.append(text1_en)\n",
        "    #         train2_en.append(text2_en)\n",
        "    #         train1_zh.append(text1_zh)\n",
        "    #         train2_zh.append(text2_zh)\n",
        "    #         y_train.append(label)\n",
        "    #\n",
        "    # # new_data_zh, _ = make_new_data(id1_train, id2_train, train1_zh, train2_zh, y_train)\n",
        "    # # print(len(new_data_zh))\n",
        "    # # for text1, text2, label in new_data_zh:\n",
        "    # #         train1_zh.append(text1)\n",
        "    # #         train2_zh.append(text2)\n",
        "    # #\n",
        "    #\n",
        "    # val1_en, val2_en = list(val_df[\"title1_en\"]), list(val_df[\"title2_en\"])\n",
        "    # val1_zh, val2_zh = list(val_df[\"title1_zh\"]), list(val_df[\"title2_zh\"])\n",
        "    # y_val = list(val_df[\"label\"])\n",
        "    #\n",
        "    # assert len(train1_zh)==len(train1_en)  and len(y_train)==len(train1_zh)\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    # print(\"training data:{}, validation data:{}\".format(len(y_train), len(y_val)))\n",
        "\n",
        "    return 0\n",
        "\n",
        "    # return (train1_en, val1_en, train1_zh, val1_zh, train2_en, val2_en,train2_zh, val2_zh, y_train, y_val)\n",
        "if isPreprocess==True:\n",
        "    preprocess_()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 8647/320552 [00:00<00:03, 86467.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0    there are two new old - age insurance benefits...\n",
            "1    if you do not come to shenzhen sooner or later...\n",
            "2    if you do not come to shenzhen sooner or later...\n",
            "3    if you do not come to shenzhen sooner or later...\n",
            "4    how to discriminate oil from gutter oil by mea...\n",
            "Name: title1_en, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 320552/320552 [00:02<00:00, 110104.05it/s]\n",
            "100%|██████████| 80126/80126 [00:00<00:00, 109490.65it/s]\n",
            "100%|██████████| 320552/320552 [00:03<00:00, 84215.54it/s]\n",
            "100%|██████████| 80126/80126 [00:00<00:00, 85789.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the number of english words:42813, chinese words:5218\n",
            "cleaned df, word to ix saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hdi8EtXbT3YQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**MODELS**"
      ]
    },
    {
      "metadata": {
        "id": "ZxRQhitgLS6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "\n",
        "class LSTM_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size_en, vocab_size_zh, target_size=3, seq_length_en=50, seq_length_zh=140):\n",
        "        super(LSTM_Classifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.word_embeddings_en = nn.Embedding(vocab_size_en+1, embedding_dim, padding_idx=0)\n",
        "        self.word_embeddings_zh = nn.Embedding(vocab_size_zh+1, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm_en = nn.LSTM(embedding_dim, hidden_dim, batch_first=False, num_layers=2)\n",
        "        self.lstm_zh = nn.LSTM(embedding_dim, hidden_dim, batch_first=False, num_layers=2)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim*2)\n",
        "        self.fc1_drop = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_dim*2, target_size)\n",
        "        self.initial_hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "        self.seq_length_en=seq_length_en\n",
        "        self.seq_length_zh=seq_length_zh\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
        "        return (torch.zeros(1, 1, self.hidden_dim),\n",
        "                torch.zeros(1, 1, self.hidden_dim))\n",
        "\n",
        "    def forward(self, title1_en, title2_en, title1_zh, title2_zh):\n",
        "        batch = title1_en.shape[0]\n",
        "\n",
        "        embeds1_en = self.word_embeddings_en(title1_en)\n",
        "        embeds2_en = self.word_embeddings_en(title2_en)\n",
        "\n",
        "        embeds1_zh = self.word_embeddings_zh(title1_zh)\n",
        "        embeds2_zh = self.word_embeddings_zh(title2_zh)\n",
        "\n",
        "        # seq_length * batch * feature_dims\n",
        "        embeds1_en = embeds1_en.view(self.seq_length_en, batch, self.embedding_dim)\n",
        "        embeds2_en = embeds2_en.view(self.seq_length_en, batch, self.embedding_dim)\n",
        "\n",
        "        embeds1_zh = embeds1_zh.view(self.seq_length_zh, batch, self.embedding_dim)\n",
        "        embeds2_zh = embeds2_zh.view(self.seq_length_zh, batch, self.embedding_dim)\n",
        "\n",
        "        #print(\"embeds1_en\", embeds1_en.size())\n",
        "\n",
        "        lstm_out1_en, self.hidden = self.lstm_en(embeds1_en)#, self.initial_hidden)\n",
        "        lstm_out2_en, self.hidden = self.lstm_en(embeds2_en)\n",
        "        lstm_out1_zh, self.hidden = self.lstm_zh(embeds1_zh)\n",
        "        lstm_out2_zh, self.hidden = self.lstm_zh(embeds1_zh)\n",
        "\n",
        "        en_sum = lstm_out1_en[-1] + lstm_out2_en[-1]\n",
        "        zh_sum = lstm_out1_zh[-1] + lstm_out2_zh[-1]\n",
        "        #print(\"embedding size:\",en_sum.size(), zh_sum.size())\n",
        "\n",
        "        concat = torch.cat((en_sum, zh_sum), dim=1)\n",
        "        #print(\"lstm out:\", lstm_out1[-1].size())\n",
        "        #print(\"concat:\", concat.size())\n",
        "\n",
        "        fc1 = self.fc1_drop(F.relu(self.fc1(concat)))\n",
        "        fc2 = self.fc2(fc1)\n",
        "\n",
        "        return fc2\n",
        "\n",
        "\n",
        "\n",
        "class MLP_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, vocab_size, target_size=3, seq_length=50):\n",
        "        super(MLP_Classifier, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, embedding_dim, padding_idx=0)\n",
        "\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.fc1 = nn.Linear(embedding_dim*2, embedding_dim*2)\n",
        "        self.fc1_bn = nn.BatchNorm1d(embedding_dim*2)\n",
        "        self.fc1_drop = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        self.fc2 = nn.Linear(embedding_dim*2, target_size)\n",
        "\n",
        "        self.seq_length=seq_length\n",
        "\n",
        "    def forward(self, sentence1, sentence2):\n",
        "        embeds1 = self.word_embeddings(sentence1)\n",
        "        embeds1 = torch.sum(embeds1, 1)\n",
        "        #print(\"embed\", embeds1.size())\n",
        "\n",
        "\n",
        "        embeds2 = self.word_embeddings(sentence2)\n",
        "        embeds2 = torch.sum(embeds2, 1)\n",
        "\n",
        "        #print(\"embedding size:\",embeds1.size(), len(sentence1))\n",
        "\n",
        "        #embeds1 = embeds1.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
        "        #embeds2 = embeds2.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
        "\n",
        "        concat = torch.cat((embeds1, embeds2), dim=1)\n",
        "        #print(\"concat:\", concat.size())\n",
        "\n",
        "        fc1 = self.fc1_drop(F.relu(self.fc1_bn(self.fc1(concat))))\n",
        "        fc2 = self.fc2(fc1)\n",
        "\n",
        "        return fc2\n",
        "\n",
        "#Combine English and Chinese.\n",
        "\n",
        "class Twolang_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, vocab_size_en, vocab_size_zh, target_size=3, seq_length_en=50, seq_length_zh=100, kernel_num=64):\n",
        "        super(Twolang_Classifier, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.seq_length_en=seq_length_en\n",
        "        self.seq_length_zh=seq_length_zh\n",
        "\n",
        "        self.word_embeddings_en = nn.Embedding(vocab_size_en+1, embedding_dim, padding_idx=0)\n",
        "        self.word_embeddings_zh = nn.Embedding(vocab_size_zh+1, embedding_dim, padding_idx=0)\n",
        "\n",
        "\n",
        "        self.kernel_num=kernel_num\n",
        "        self.conv2_en = nn.Conv2d(1, kernel_num, (2, embedding_dim))\n",
        "        self.conv3_en = nn.Conv2d(1, kernel_num, (3, embedding_dim))\n",
        "        self.conv4_en = nn.Conv2d(1, kernel_num, (4, embedding_dim))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(1, kernel_num, (2, embedding_dim))\n",
        "        self.conv3 = nn.Conv2d(1, kernel_num, (3, embedding_dim))\n",
        "        self.conv4 = nn.Conv2d(1, kernel_num, (4, embedding_dim))\n",
        "        #self.conv5 = nn.Conv2d(1, kernel_num, (5, embedding_dim))\n",
        "\n",
        "        self.Max2_pool_en = nn.MaxPool2d((self.seq_length_en-2+1, 1))\n",
        "        self.Max3_pool_en = nn.MaxPool2d((self.seq_length_en-3+1, 1))\n",
        "        self.Max4_pool_en = nn.MaxPool2d((self.seq_length_en-4+1, 1))\n",
        "        #self.Max5_pool = nn.MaxPool2d((self.seq_length-5+1, 1))\n",
        "        self.Max2_pool = nn.MaxPool2d((self.seq_length_zh-2+1, 1))\n",
        "        self.Max3_pool = nn.MaxPool2d((self.seq_length_zh-3+1, 1))\n",
        "        self.Max4_pool = nn.MaxPool2d((self.seq_length_zh-4+1, 1))\n",
        "\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        #self.fc1 = nn.Linear(embedding_dim*4, embedding_dim*4)\n",
        "        #self.fc1_bn = nn.BatchNorm1d(embedding_dim*4)\n",
        "        # self.fc1 = nn.Linear(embedding_dim+kernel_num*3, embedding_dim+kernel_num*3)\n",
        "        self.fc1 = nn.Linear(kernel_num*6, kernel_num*6)\n",
        "\n",
        "        self.fc1_bn = nn.BatchNorm1d(kernel_num*6)\n",
        "        self.fc1_drop = nn.Dropout(p=0.5, inplace=False)\n",
        "\n",
        "        self.fc2 = nn.Linear(kernel_num*6, target_size)\n",
        "\n",
        "\n",
        "    def forward(self, title1_en, title2_en, title1_zh, title2_zh):\n",
        "        batch = title1_en.shape[0]\n",
        "\n",
        "        embeds1_en = self.word_embeddings_en(title1_en)\n",
        "        #embeds1_en = torch.sum(embeds1_en, 1)\n",
        "        embeds1_en = embeds1_en.view(batch, 1, self.seq_length_en, self.embedding_dim)\n",
        "\n",
        "        embeds2_en = self.word_embeddings_en(title2_en)\n",
        "        #embeds2_en = torch.sum(embeds2_en, 1)\n",
        "        embeds2_en = embeds2_en.view(batch, 1, self.seq_length_en, self.embedding_dim)\n",
        "\n",
        "        #Convolution\n",
        "        embeds1_x2 = F.relu(self.conv2_en(embeds1_en))\n",
        "        embeds1_x3 = F.relu(self.conv3_en(embeds1_en))\n",
        "        embeds1_x4 = F.relu(self.conv4_en(embeds1_en))\n",
        "        #embeds1_x5 = F.relu(self.conv5(embeds1_zh))\n",
        "\n",
        "        embeds2_x2 = F.relu(self.conv2_en(embeds2_en))\n",
        "        embeds2_x3 = F.relu(self.conv3_en(embeds2_en))\n",
        "        embeds2_x4 = F.relu(self.conv4_en(embeds2_en))\n",
        "        #embeds2_x5 = F.relu(self.conv5(embeds2_zh))\n",
        "\n",
        "        # Pooling\n",
        "        embeds1_x2 = self.Max2_pool_en(embeds1_x2).view(batch, -1)\n",
        "        embeds1_x3 = self.Max3_pool_en(embeds1_x3).view(batch, -1)\n",
        "        embeds1_x4 = self.Max4_pool_en(embeds1_x4).view(batch, -1)\n",
        "        #embeds1_x5 = self.Max5_pool(embeds1_x5).view(batch, -1)\n",
        "\n",
        "        embeds2_x2 = self.Max2_pool_en(embeds2_x2).view(batch, -1)\n",
        "        embeds2_x3 = self.Max3_pool_en(embeds2_x3).view(batch, -1)\n",
        "        embeds2_x4 = self.Max4_pool_en(embeds2_x4).view(batch, -1)\n",
        "        #embeds2_x5 = self.Max5_pool(embeds2_x5).view(batch, -1)\n",
        "\n",
        "\n",
        "        embeds1_en = torch.cat((embeds1_x2, embeds1_x3, embeds1_x4), dim=1)\n",
        "        embeds2_en = torch.cat((embeds2_x2, embeds2_x3, embeds2_x4), dim=1)\n",
        "\n",
        "\n",
        "        en_sum = embeds1_en + embeds2_en\n",
        "\n",
        "\n",
        "\n",
        "        embeds1_zh = self.word_embeddings_zh(title1_zh)\n",
        "        #embeds1_zh = torch.sum(embeds1_zh, 1)\n",
        "        #For CNN.\n",
        "        embeds1_zh = embeds1_zh.view(batch, 1, self.seq_length_zh, self.embedding_dim)\n",
        "\n",
        "        embeds2_zh = self.word_embeddings_zh(title2_zh)\n",
        "        #embeds2_zh = torch.sum(embeds2_zh, 1)\n",
        "        #For CNN.\n",
        "        embeds2_zh = embeds2_zh.view(batch, 1, self.seq_length_zh, self.embedding_dim)\n",
        "\n",
        "        #Convolution\n",
        "        embeds1_x2 = F.relu(self.conv2(embeds1_zh))\n",
        "        embeds1_x3 = F.relu(self.conv3(embeds1_zh))\n",
        "        embeds1_x4 = F.relu(self.conv4(embeds1_zh))\n",
        "        #embeds1_x5 = F.relu(self.conv5(embeds1_zh))\n",
        "\n",
        "        embeds2_x2 = F.relu(self.conv2(embeds2_zh))\n",
        "        embeds2_x3 = F.relu(self.conv3(embeds2_zh))\n",
        "        embeds2_x4 = F.relu(self.conv4(embeds2_zh))\n",
        "        #embeds2_x5 = F.relu(self.conv5(embeds2_zh))\n",
        "\n",
        "        # Pooling\n",
        "        embeds1_x2 = self.Max2_pool(embeds1_x2).view(batch, -1)\n",
        "        embeds1_x3 = self.Max3_pool(embeds1_x3).view(batch, -1)\n",
        "        embeds1_x4 = self.Max4_pool(embeds1_x4).view(batch, -1)\n",
        "        #embeds1_x5 = self.Max5_pool(embeds1_x5).view(batch, -1)\n",
        "\n",
        "        embeds2_x2 = self.Max2_pool(embeds2_x2).view(batch, -1)\n",
        "        embeds2_x3 = self.Max3_pool(embeds2_x3).view(batch, -1)\n",
        "        embeds2_x4 = self.Max4_pool(embeds2_x4).view(batch, -1)\n",
        "        #embeds2_x5 = self.Max5_pool(embeds2_x5).view(batch, -1)\n",
        "\n",
        "\n",
        "        embeds1_zh = torch.cat((embeds1_x2, embeds1_x3, embeds1_x4), dim=1)\n",
        "        embeds2_zh = torch.cat((embeds2_x2, embeds2_x3, embeds2_x4), dim=1)\n",
        "\n",
        "        zh_sum = embeds1_zh + embeds2_zh\n",
        "\n",
        "        #print(\"embedding size:\",embeds1.size(), len(sentence1))\n",
        "\n",
        "        #embeds1 = embeds1.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
        "        #embeds2 = embeds2.view(self.seq_length, len(sentence1), self.embedding_dim)\n",
        "\n",
        "        #concat = torch.cat((embeds1_en, embeds2_en, embeds1_zh, embeds2_zh), dim=1)\n",
        "        concat = torch.cat((en_sum, zh_sum), dim=1)\n",
        "\n",
        "        fc1 = self.fc1_drop(F.relu(self.fc1_bn(self.fc1(concat))))\n",
        "        fc2 = self.fc2(fc1)\n",
        "\n",
        "        return fc2\n",
        "\n",
        "\n",
        "class Text_CNN_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, vocab_size, target_size=3, seq_length=50):\n",
        "        super(Text_CNN_Classifier, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, embedding_dim, padding_idx=0)\n",
        "        self.seq_length=seq_length\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(1, 1, (3, embedding_dim))\n",
        "        self.conv4_1 = nn.Conv2d(1, 1, (4, embedding_dim))\n",
        "        self.conv5_1 = nn.Conv2d(1, 3, (5, embedding_dim))\n",
        "        self.conv3_2 = nn.Conv2d(1, 1, (3, embedding_dim))\n",
        "        self.conv4_2 = nn.Conv2d(1, 1, (4, embedding_dim))\n",
        "        self.conv5_2 = nn.Conv2d(1, 1, (5, embedding_dim))\n",
        "\n",
        "        self.Max3_pool = nn.MaxPool2d((self.seq_length-3+1, 1))\n",
        "        self.Max4_pool = nn.MaxPool2d((self.seq_length-4+1, 1))\n",
        "        self.Max5_pool = nn.MaxPool2d((self.seq_length-5+1, 1))\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.fc1 = nn.Linear(6, target_size)\n",
        "\n",
        "\n",
        "    def forward(self, sentence1, sentence2):\n",
        "        batch = len(sentence1)\n",
        "        embeds1 = self.word_embeddings(sentence1)\n",
        "        embeds2 = self.word_embeddings(sentence2)\n",
        "\n",
        "        embeds1 = embeds1.view(len(sentence1), 1, self.seq_length, self.embedding_dim)\n",
        "        embeds2 = embeds2.view(len(sentence2), 1, self.seq_length, self.embedding_dim)\n",
        "\n",
        "        # Convolution\n",
        "        embeds1_x1 = F.relu(self.conv3_1(embeds1))\n",
        "        embeds1_x2 = F.relu(self.conv4_1(embeds1))\n",
        "        embeds1_x3 = F.relu(self.conv5_1(embeds1))\n",
        "    #         embeds2_x1 = F.relu(self.conv3_2(embeds2))\n",
        "    #         embeds2_x2 = F.relu(self.conv4_2(embeds2))\n",
        "    #         embeds2_x3 = F.relu(self.conv5_2(embeds2))\n",
        "        embeds2_x1 = F.relu(self.conv3_1(embeds2))\n",
        "        embeds2_x2 = F.relu(self.conv4_1(embeds2))\n",
        "        embeds2_x3 = F.relu(self.conv5_1(embeds2))\n",
        "\n",
        "        # Pooling\n",
        "        embeds1_x1 = self.Max3_pool(embeds1_x1)\n",
        "        embeds1_x2 = self.Max4_pool(embeds1_x2)\n",
        "        embeds1_x3 = self.Max5_pool(embeds1_x3)\n",
        "        embeds2_x1 = self.Max3_pool(embeds2_x1)\n",
        "        embeds2_x2 = self.Max4_pool(embeds2_x2)\n",
        "        embeds2_x3 = self.Max5_pool(embeds2_x3)\n",
        "\n",
        "        #print(\"max pool size:\", embeds2_x3.size())\n",
        "\n",
        "        concat = torch.cat((embeds1_x1, embeds1_x2, embeds1_x3, embeds2_x1, embeds2_x2, embeds2_x3), -1)\n",
        "        x = concat.view(batch, -1)\n",
        "        #print(\"concat:\", x.size())\n",
        "\n",
        "        fc1 = self.fc1(x)\n",
        "        #print(\"fc1:\", fc1.size())\n",
        "\n",
        "        return fc1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EoezRZ6EY66V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DATASET**"
      ]
    },
    {
      "metadata": {
        "id": "-8X6Q1LjYyUu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, titles1_en, titles2_en, labels, tokenizer, seq_length=100):\n",
        "\n",
        "        self.titles1_en = titles1_en\n",
        "        self.titles2_en = titles2_en\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length=seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.titles1_en)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq_length = self.seq_length\n",
        "        tokenizer = self.tokenizer\n",
        "\n",
        "        title1_en = self.titles1_en[idx]\n",
        "        tokens_a = tokenizer.tokenize(title1_en)\n",
        "        #indexed_tokens_title1_en = tokenizer.convert_tokens_to_ids(tokenized_title1_en)\n",
        "\n",
        "\n",
        "        title2_en = self.titles2_en[idx]\n",
        "        tokens_b = tokenizer.tokenize(title2_en)\n",
        "        #indexed_tokens_title2_en = tokenizer.convert_tokens_to_ids(tokenized_title2_en)\n",
        "\n",
        "\n",
        "\n",
        "        def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "            \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "            # This is a simple heuristic which will always truncate the longer sequence\n",
        "            # one token at a time. This makes more sense than truncating an equal percent\n",
        "            # of tokens from each, since if one sequence is very short then each token\n",
        "            # that's truncated likely contains more information than a longer sequence.\n",
        "            while True:\n",
        "                total_length = len(tokens_a) + len(tokens_b)\n",
        "                if total_length <= max_length:\n",
        "                    break\n",
        "                if len(tokens_a) > len(tokens_b):\n",
        "                    tokens_a.pop()\n",
        "                else:\n",
        "                    tokens_b.pop()\n",
        "\n",
        "\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, seq_length-3)\n",
        "\n",
        "\n",
        "        tokens = []\n",
        "        input_type_ids = []\n",
        "\n",
        "        tokens.append(\"[CLS]\")\n",
        "        input_type_ids.append(0)\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "            input_type_ids.append(0)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        input_type_ids.append(0)\n",
        "\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "            input_type_ids.append(1)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        input_type_ids.append(1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero padding.\n",
        "        while len(input_ids) < seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            input_type_ids.append(0)\n",
        "\n",
        "\n",
        "        #print(\"input_ids:{}, input_mask:{}, input_type_ids:{}\".format(len(input_ids), len(input_mask), len(input_type_ids)))\n",
        "        assert len(input_ids) == seq_length\n",
        "        assert len(input_mask) == seq_length\n",
        "        assert len(input_type_ids) == seq_length\n",
        "\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        input_mask = torch.tensor(input_mask)\n",
        "        input_type_ids = torch.tensor(input_type_ids)\n",
        "        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "\n",
        "        #\n",
        "        #\n",
        "        # tokens_tensor = torch.tensor(indexed_tokens_title1_en + indexed_tokens_title2_en)\n",
        "        # segments_tensor = torch.tensor(len(indexed_tokens_title1_en) * [0] + len(indexed_tokens_title2_en) * [1])\n",
        "        #\n",
        "        # assert len(tokens_tensor) == len(segments_ids)\n",
        "        #\n",
        "        # label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        #\n",
        "        sample = {'input_ids': input_ids, 'input_mask': input_mask,\n",
        "                    'input_type_ids':input_type_ids, 'label': labels}\n",
        "\n",
        "        # if self.transform:\n",
        "        #     sample = self.transform(sample, self.dic_en, self.dic_zh, self.seq_length_en, self.seq_length_zh)\n",
        "\n",
        "        return sample\n",
        "\n",
        "# Dataset\n",
        "class TitleDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, titles1_en, titles2_en,\n",
        "    titles1_zh, titles2_zh, labels, dic_en=None, dic_zh=None,\n",
        "    transform=None, seq_length_en=50, seq_length_zh=140,\n",
        "    if_test=False):\n",
        "\n",
        "        self.titles1_en = titles1_en\n",
        "        self.titles2_en = titles2_en\n",
        "        self.titles1_zh = titles1_zh\n",
        "        self.titles2_zh = titles2_zh\n",
        "\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.dic_en=dic_en\n",
        "        self.dic_zh=dic_zh\n",
        "\n",
        "        self.seq_length_en=seq_length_en\n",
        "        self.seq_length_zh=seq_length_zh\n",
        "\n",
        "        self.if_test=if_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.titles1_en)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        title1_en = self.titles1_en[idx]\n",
        "        title2_en = self.titles2_en[idx]\n",
        "        title1_zh = self.titles1_zh[idx]\n",
        "        title2_zh = self.titles2_zh[idx]\n",
        "\n",
        "        if self.if_test:\n",
        "            # dummy label\n",
        "            label = title1_en\n",
        "        else:\n",
        "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        sample = {'t1_en': title1_en, 't2_en': title2_en, 't1_zh': title1_zh, 't2_zh': title2_zh, 'label': label}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample, self.dic_en, self.dic_zh, self.seq_length_en, self.seq_length_zh)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Toidx(object):\n",
        "    def __call__(self, sample, word_to_idx_en, word_to_idx_zh, max_seq_length_en, max_seq_length_zh):\n",
        "\n",
        "        def prepare_sequence(seq, to_ix, max_seq_length, language=\"english\"):\n",
        "            seq = str(seq)\n",
        "            #zero padding and word--->ix in seq.\n",
        "            if language == \"english\":\n",
        "                idxs = [to_ix[w] for w in seq.split()]\n",
        "            elif language == \"chinese\":\n",
        "                idxs = [to_ix[w] for w in seq]\n",
        "\n",
        "\n",
        "            if len(idxs) > max_seq_length:\n",
        "                idxs = idxs[:max_seq_length]\n",
        "            else:\n",
        "                idxs += [0] * (max_seq_length - len(idxs))\n",
        "            return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "        t1_en, t2_en, t1_zh, t2_zh, label = sample['t1_en'], sample['t2_en'], sample['t1_zh'], sample['t2_zh'], sample[\"label\"]\n",
        "        return {'t1_en': prepare_sequence(t1_en, word_to_idx_en, max_seq_length_en, language=\"english\"),\n",
        "                    't2_en': prepare_sequence(t2_en, word_to_idx_en, max_seq_length_en,language=\"english\"),\n",
        "                    't1_zh': prepare_sequence(t1_zh, word_to_idx_zh, max_seq_length_zh,language=\"chinese\"),\n",
        "                    't2_zh': prepare_sequence(t2_zh, word_to_idx_zh, max_seq_length_zh,language=\"chinese\"),\n",
        "                    'label': label}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UCY-5n4bWiBl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TRAIN**"
      ]
    },
    {
      "metadata": {
        "id": "zSMqomonWnnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "#from preprocess import preprocess_, make_new_data\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, sample_batch in enumerate((train_loader)):\n",
        "        #print(\"batch_idx:\",batch_idx)\n",
        "        en_title1 = sample_batch[\"t1_en\"].to(device)\n",
        "        en_title2 = sample_batch[\"t2_en\"].to(device)\n",
        "        zh_title1 = sample_batch[\"t1_zh\"].to(device)\n",
        "        zh_title2 = sample_batch[\"t2_zh\"].to(device)\n",
        "        y = sample_batch[\"label\"].to(device)\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(en_title1, en_title2, zh_title1, zh_title2)\n",
        "\n",
        "        loss = loss_function(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "        #outputs = model(en_title2, en_title1)\n",
        "\n",
        "        #loss = loss_function(outputs, y)\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "\n",
        "    print(\"epoch:{},train_loss:{:.4f}\".format(epoch+1 ,loss))\n",
        "    #print(\"train data all :\", (batch_idx+1)*batch)\n",
        "    return model\n",
        "\n",
        "def test():\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, sample_batch in enumerate(val_loader):\n",
        "            en_title1 = sample_batch[\"t1_en\"].to(device)\n",
        "            en_title2 = sample_batch[\"t2_en\"].to(device)\n",
        "            zh_title1 = sample_batch[\"t1_zh\"].to(device)\n",
        "            zh_title2 = sample_batch[\"t2_zh\"].to(device)\n",
        "            y = sample_batch[\"label\"].to(device)\n",
        "\n",
        "            output = model(en_title1, en_title2, zh_title1, zh_title2)\n",
        "\n",
        "            # sum up batch loss\n",
        "            test_loss += weighted_loss_function(output, y).item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "        #test_loss /= len(val_loader.dataset)\n",
        "        test_loss /= batch_idx+1\n",
        "        #accuracy = 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "        accuracy = weighted_accuracy(pred, y)\n",
        "\n",
        "        print('Validation set: Weighted loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'\n",
        "              .format(test_loss, correct, len(val_loader.dataset),\n",
        "                      accuracy))\n",
        "\n",
        "        return test_loss, accuracy\n",
        "\n",
        "\n",
        "def weighted_accuracy(pred, true):\n",
        "    true = true.cpu().numpy()\n",
        "    pred = pred.cpu().numpy()\n",
        "\n",
        "    class_weight = [1/16, 1/15, 1/5]\n",
        "    score = 0\n",
        "    perfect_score = 0\n",
        "\n",
        "    for p, t in zip(pred, true):\n",
        "        if p == t:\n",
        "            if t == 0:\n",
        "                score += 1/16\n",
        "                perfect_score += 1/16\n",
        "            elif t == 1:\n",
        "                score += 1/15\n",
        "                perfect_score += 1/15\n",
        "            elif t == 2:\n",
        "                score += 1/5\n",
        "                perfect_score += 1/5\n",
        "        else:\n",
        "            if t == 0:\n",
        "                perfect_score += 1/16\n",
        "            elif t == 1:\n",
        "                perfect_score += 1/15\n",
        "            elif t == 2:\n",
        "                perfect_score += 1/5\n",
        "    #print(\"score:{}, ideal:{}\".format(score, perfect_score))\n",
        "    return 100 * score/perfect_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_model(model, val_accuracy, save_path=data_dir + 'model'):\n",
        "   # if os.path.exists(path + \"*.model\"):\n",
        "   #     os.remove(path + \"*.model\")\n",
        "    name = \"{}fold_mlp.model\".format(fold)\n",
        "    PATH = os.path.join(save_path, name)\n",
        "    torch.save(model, PATH)\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UW_Zbc5DDKSF",
        "colab_type": "code",
        "outputId": "9f83a65c-246a-4e23-f61f-2f55d6410bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "train_df = pd.read_csv(data_dir + \"train.csv\")\n",
        "FOLDS_PATH = None\n",
        "if FOLDS_PATH is None:\n",
        "    folds = KFold(n_splits=5, shuffle=False, random_state=42)\n",
        "    folds_idx = [(train_idx, val_idx) \n",
        "                 for train_idx, val_idx in folds.split(train_df)]\n",
        "\n",
        "    with open(data_dir + 'save/5Kfolds.pkl', mode='wb') as f:\n",
        "        pickle.dump(folds_idx, f)\n",
        "print (folds_idx)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import KFold\\n\\ntrain_df = pd.read_csv(data_dir + \"train.csv\")\\nFOLDS_PATH = None\\nif FOLDS_PATH is None:\\n    folds = KFold(n_splits=5, shuffle=False, random_state=42)\\n    folds_idx = [(train_idx, val_idx) \\n                 for train_idx, val_idx in folds.split(train_df)]\\n\\n    with open(data_dir + \\'save/5Kfolds.pkl\\', mode=\\'wb\\') as f:\\n        pickle.dump(folds_idx, f)\\nprint (folds_idx)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "nTMaEJ38T6pP",
        "colab_type": "code",
        "outputId": "6796daa1-af3f-4192-c5fd-e3b1740fb6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        }
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 256\n",
        "max_seq_en = 50\n",
        "max_seq_zh = 100\n",
        "EPOCH=9\n",
        "\n",
        "batch=1024\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\",device)\n",
        "\n",
        "# with open('save/word_to_ix_en.pickle', mode='rb') as f:\n",
        "#      word_to_ix_en = pickle.load(f)\n",
        "# with open('save/word_to_ix_zh.pickle', mode='rb') as f:\n",
        "#      word_to_ix_zh = pickle.load(f)\n",
        "\n",
        "print(\"@preprocessing..\")\n",
        "#_ = preprocess_()\n",
        "\n",
        "# Data loading\n",
        "with open(data_dir + 'save/word_to_ix_en.pickle', mode='rb') as f:\n",
        "     word_to_ix_en = pickle.load(f)\n",
        "with open(data_dir + 'save/word_to_ix_zh.pickle', mode='rb') as f:\n",
        "     word_to_ix_zh = pickle.load(f)\n",
        "with open(data_dir + 'save/train_df.pickle', mode='rb') as f:\n",
        "     train_df = pickle.load(f)\n",
        "with open(data_dir + 'save/test_df.pickle', mode='rb') as f:\n",
        "     test_df = pickle.load(f)\n",
        "train_df = train_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
        "\n",
        "fold_num = 5\n",
        "kf = KFold(n_splits=fold_num, random_state = 42)\n",
        "kf.get_n_splits(train_df)\n",
        "\n",
        "train_data_list = []\n",
        "val_data_list = []\n",
        "\n",
        "\n",
        "'''\n",
        "for train_index, val_index in kf.split(train_df):\n",
        "    training_df = train_df.iloc[train_index]\n",
        "    val_df = train_df.iloc[val_index]\n",
        "\n",
        "    new_data, _, _, _ = make_new_data(training_df)\n",
        "    train1_en, train2_en = [],[]\n",
        "    train1_zh, train2_zh = [],[]\n",
        "    y_train = []\n",
        "    for text1_en, text2_en, text1_zh, text2_zh,label in new_data:\n",
        "            train1_en.append(text1_en)\n",
        "            train2_en.append(text2_en)\n",
        "            train1_zh.append(text1_zh)\n",
        "            train2_zh.append(text2_zh)\n",
        "            y_train.append(label)\n",
        "    val1_en, val2_en = list(val_df[\"title1_en\"]), list(val_df[\"title2_en\"])\n",
        "    val1_zh, val2_zh = list(val_df[\"title1_zh\"]), list(val_df[\"title2_zh\"])\n",
        "    y_val = list(val_df[\"label\"])\n",
        "\n",
        "    train_data_list.append((train1_en,train2_en,train1_zh,train2_zh,y_train))\n",
        "    val_data_list.append((val1_en, val2_en,val1_zh, val2_zh,y_val))\n",
        "with open(data_dir + 'save/kfold_train_data.pickle', mode='wb') as f:\n",
        "    pickle.dump(train_data_list, f)\n",
        "with open(data_dir + 'save/kfold_val_data.pickle', mode='wb') as f:\n",
        "    pickle.dump(val_data_list, f)\n",
        "'''   \n",
        "\n",
        "\n",
        "with open(data_dir + 'save/kfold_train_data.pickle', mode='rb') as f:\n",
        "     train_data_list = pickle.load(f)\n",
        "with open(data_dir + 'save/kfold_val_data.pickle', mode='rb') as f:\n",
        "     val_data_list = pickle.load(f)\n",
        "\n",
        "PATH = data_dir+ \"model/MLP.model\"\n",
        "PATH_list = [data_dir + \"model/{}fold_mlp.model\".format(fold) for fold in range(1,6,1)]\n",
        "\n",
        "folds_accuracies = []\n",
        "Pretrained = False\n",
        "fold=1\n",
        "for train_fold, val_fold in zip(train_data_list,val_data_list):\n",
        "    print(\"{}/{} fold :\".format(fold, fold_num))\n",
        "    print(\"train length:{}, val length:{}\".format(len(train_fold[0]), len(val_fold[0])))\n",
        "\n",
        "    (train1_en,train2_en,train1_zh,train2_zh,y_train) = train_fold\n",
        "    (val1_en, val2_en,val1_zh, val2_zh,y_val) = val_fold\n",
        " \n",
        "    # Class weight gan be got as : n_samples / (n_classes * np.bincount(y))\n",
        "    c = Counter(y_train)\n",
        "    class_weight = []\n",
        "    for label, num in sorted(c.items()):\n",
        "        print(label, num)\n",
        "        class_weight.append(len(y_train)/(3*num))\n",
        "    #class_weight = torch.FloatTensor(class_weight).to(device)\n",
        "    #print(\"class weight:\", class_weight)\n",
        "\n",
        "    model = LSTM_Classifier(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix_en), len(word_to_ix_zh), target_size=3, seq_length_en=max_seq_en,seq_length_zh=max_seq_zh)\n",
        "    #model = MLP_Classifier(EMBEDDING_DIM, len(word_to_ix_en), target_size=3, seq_length=max_seq_en)\n",
        "    #model = Text_CNN_Classifier(EMBEDDING_DIM, len(word_to_ix_en), target_size=3, seq_length=max_seq_length)\n",
        "    \n",
        "    #model = Twolang_Classifier(EMBEDDING_DIM, len(word_to_ix_en),len(word_to_ix_zh), target_size=3, kernel_num=64)\n",
        "\n",
        "    model.to(device)\n",
        "    train_dataset = TitleDataset(train1_en, train2_en, train1_zh, train2_zh, y_train,\n",
        "                                 dic_en=word_to_ix_en, dic_zh=word_to_ix_zh, transform=Toidx(),\n",
        "                                 seq_length_en=max_seq_en, seq_length_zh=max_seq_zh)\n",
        "\n",
        "    val_dataset = TitleDataset(val1_en, val2_en, val1_zh, val2_zh, y_val,\n",
        "                               dic_en=word_to_ix_en, dic_zh=word_to_ix_zh, transform=Toidx(),\n",
        "                               seq_length_en=max_seq_en, seq_length_zh=max_seq_zh)\n",
        "\n",
        "\n",
        "    class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in y_train])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weight = samples_weight.double()\n",
        "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=False, sampler=sampler)#, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
        "    loss_function = nn.CrossEntropyLoss()#weight=class_weight)\n",
        "    weighted_loss_function = nn.CrossEntropyLoss()#weight=class_weight)\n",
        "\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = CosineAnnealingLR(optimizer, len(train_loader), eta_min = 0.001/10)\n",
        "\n",
        "    lowest_loss = 1000000000\n",
        "    highest_accuracy = 0\n",
        "    for epoch in range(EPOCH):\n",
        "        #print(epoch+1)\n",
        "        if Pretrained == True and highest_accuracy == 0:\n",
        "                name = \"{}fold_mlp.model\".format(fold)\n",
        "                PATH = os.path.join(data_dir + 'model', name)\n",
        "                model = torch.load(PATH)             \n",
        "                print ('Pretrained model loaded')\n",
        "        model = train(epoch)\n",
        "        val_loss, accuracy = test()\n",
        "\n",
        "    #     if val_loss < lowest_loss:\n",
        "    #         lowest_loss = val_loss\n",
        "    #         save_model(model)\n",
        "    \n",
        "        if accuracy > highest_accuracy:\n",
        "            #print(\"saving model...\")\n",
        "            highest_accuracy = accuracy\n",
        "            save_model(model, highest_accuracy)\n",
        "        print(\"highest_accuracy:{:.2f}% \\n\".format(highest_accuracy), 'current lr: ', get_lr(optimizer))\n",
        "    folds_accuracies.append(highest_accuracy)\n",
        "        #break\n",
        "    fold +=1\n",
        "print ('Final mean accuracy: ', np.mean(folds_accuracies))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "@preprocessing..\n",
            "1/5 fold :\n",
            "train length:263272, val length:64111\n",
            "0 175184\n",
            "1 74249\n",
            "2 13839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0936\n",
            "Validation set: Weighted loss: 1.1045, Accuracy: 12800/64111 (17.52%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type LSTM_Classifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "highest_accuracy:17.52% \n",
            " current lr:  0.00010003336087903097\n",
            "epoch:2,train_loss:1.0994\n",
            "Validation set: Weighted loss: 1.1034, Accuracy: 11796/64111 (25.44%)\n",
            "highest_accuracy:25.44% \n",
            " current lr:  0.000999966639120969\n",
            "epoch:3,train_loss:1.1019\n",
            "Validation set: Weighted loss: 1.1032, Accuracy: 8310/64111 (18.15%)\n",
            "highest_accuracy:25.44% \n",
            " current lr:  0.00010003336087903097\n",
            "epoch:4,train_loss:1.0992\n",
            "Validation set: Weighted loss: 1.1005, Accuracy: 18324/64111 (26.17%)\n",
            "highest_accuracy:26.17% \n",
            " current lr:  0.000999966639120969\n",
            "epoch:5,train_loss:1.0994\n",
            "Validation set: Weighted loss: 1.0993, Accuracy: 17886/64111 (37.04%)\n",
            "highest_accuracy:37.04% \n",
            " current lr:  0.00010003336087903097\n",
            "epoch:6,train_loss:1.0982\n",
            "Validation set: Weighted loss: 1.0979, Accuracy: 18858/64111 (31.19%)\n",
            "highest_accuracy:37.04% \n",
            " current lr:  0.000999966639120969\n",
            "epoch:7,train_loss:1.0985\n",
            "Validation set: Weighted loss: 1.1001, Accuracy: 11068/64111 (9.23%)\n",
            "highest_accuracy:37.04% \n",
            " current lr:  0.00010003336087903097\n",
            "epoch:8,train_loss:1.0979\n",
            "Validation set: Weighted loss: 1.0962, Accuracy: 39346/64111 (52.24%)\n",
            "highest_accuracy:52.24% \n",
            " current lr:  0.000999966639120969\n",
            "epoch:9,train_loss:1.0989\n",
            "Validation set: Weighted loss: 1.0976, Accuracy: 23061/64111 (39.21%)\n",
            "highest_accuracy:52.24% \n",
            " current lr:  0.00010003336087903097\n",
            "2/5 fold :\n",
            "train length:262944, val length:64111\n",
            "0 175489\n",
            "1 73948\n",
            "2 13507\n",
            "epoch:1,train_loss:1.0992\n",
            "Validation set: Weighted loss: 1.0924, Accuracy: 38196/64111 (60.73%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:2,train_loss:1.0991\n",
            "Validation set: Weighted loss: 1.0939, Accuracy: 29605/64111 (51.46%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:3,train_loss:1.0982\n",
            "Validation set: Weighted loss: 1.1014, Accuracy: 15226/64111 (21.52%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:4,train_loss:1.1002\n",
            "Validation set: Weighted loss: 1.1102, Accuracy: 16204/64111 (15.48%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:5,train_loss:1.0982\n",
            "Validation set: Weighted loss: 1.0990, Accuracy: 18327/64111 (26.81%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:6,train_loss:1.0985\n",
            "Validation set: Weighted loss: 1.1013, Accuracy: 13743/64111 (25.46%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:7,train_loss:1.0989\n",
            "Validation set: Weighted loss: 1.0995, Accuracy: 7523/64111 (21.90%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:8,train_loss:1.0992\n",
            "Validation set: Weighted loss: 1.0978, Accuracy: 11646/64111 (20.55%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:9,train_loss:1.0986\n",
            "Validation set: Weighted loss: 1.0984, Accuracy: 30293/64111 (44.23%)\n",
            "highest_accuracy:60.73% \n",
            " current lr:  0.00010003362099862035\n",
            "3/5 fold :\n",
            "train length:262800, val length:64110\n",
            "0 175170\n",
            "1 74245\n",
            "2 13385\n",
            "epoch:1,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0969, Accuracy: 24538/64110 (36.31%)\n",
            "highest_accuracy:36.31% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:2,train_loss:1.1000\n",
            "Validation set: Weighted loss: 1.0965, Accuracy: 22439/64110 (36.71%)\n",
            "highest_accuracy:36.71% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:3,train_loss:1.0982\n",
            "Validation set: Weighted loss: 1.0977, Accuracy: 25035/64110 (34.46%)\n",
            "highest_accuracy:36.71% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:4,train_loss:1.0986\n",
            "Validation set: Weighted loss: 1.1037, Accuracy: 4073/64110 (10.68%)\n",
            "highest_accuracy:36.71% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:5,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0994, Accuracy: 14175/64110 (30.30%)\n",
            "highest_accuracy:36.71% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:6,train_loss:1.0982\n",
            "Validation set: Weighted loss: 1.0907, Accuracy: 27045/64110 (45.14%)\n",
            "highest_accuracy:45.14% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:7,train_loss:1.0980\n",
            "Validation set: Weighted loss: 1.0989, Accuracy: 20220/64110 (35.58%)\n",
            "highest_accuracy:45.14% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:8,train_loss:1.0978\n",
            "Validation set: Weighted loss: 1.0979, Accuracy: 26524/64110 (35.30%)\n",
            "highest_accuracy:45.14% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:9,train_loss:1.0981\n",
            "Validation set: Weighted loss: 1.1019, Accuracy: 17408/64110 (26.87%)\n",
            "highest_accuracy:45.14% \n",
            " current lr:  0.00010003362099862035\n",
            "4/5 fold :\n",
            "train length:263110, val length:64110\n",
            "0 175217\n",
            "1 74174\n",
            "2 13719\n",
            "epoch:1,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0942, Accuracy: 28322/64110 (37.67%)\n",
            "highest_accuracy:37.67% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:2,train_loss:1.0998\n",
            "Validation set: Weighted loss: 1.1062, Accuracy: 6875/64110 (19.42%)\n",
            "highest_accuracy:37.67% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:3,train_loss:1.0989\n",
            "Validation set: Weighted loss: 1.0969, Accuracy: 29312/64110 (41.20%)\n",
            "highest_accuracy:41.20% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:4,train_loss:1.0985\n",
            "Validation set: Weighted loss: 1.0929, Accuracy: 39853/64110 (53.63%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:5,train_loss:1.0986\n",
            "Validation set: Weighted loss: 1.0967, Accuracy: 36688/64110 (53.20%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:6,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0988, Accuracy: 18594/64110 (22.20%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:7,train_loss:1.0983\n",
            "Validation set: Weighted loss: 1.0975, Accuracy: 34044/64110 (53.20%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:8,train_loss:1.0979\n",
            "Validation set: Weighted loss: 1.1006, Accuracy: 18585/64110 (22.20%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:9,train_loss:1.0985\n",
            "Validation set: Weighted loss: 1.0994, Accuracy: 15315/64110 (17.08%)\n",
            "highest_accuracy:53.63% \n",
            " current lr:  0.00010003362099862035\n",
            "5/5 fold :\n",
            "train length:263017, val length:64110\n",
            "0 175190\n",
            "1 74203\n",
            "2 13624\n",
            "epoch:1,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0977, Accuracy: 21884/64110 (37.37%)\n",
            "highest_accuracy:37.37% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:2,train_loss:1.0989\n",
            "Validation set: Weighted loss: 1.1037, Accuracy: 9774/64110 (21.78%)\n",
            "highest_accuracy:37.37% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:3,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0963, Accuracy: 30519/64110 (44.63%)\n",
            "highest_accuracy:44.63% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:4,train_loss:1.0983\n",
            "Validation set: Weighted loss: 1.1079, Accuracy: 3048/64110 (9.00%)\n",
            "highest_accuracy:44.63% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:5,train_loss:1.0988\n",
            "Validation set: Weighted loss: 1.0966, Accuracy: 39168/64110 (61.85%)\n",
            "highest_accuracy:61.85% \n",
            " current lr:  0.00010003362099862035\n",
            "epoch:6,train_loss:1.0990\n",
            "Validation set: Weighted loss: 1.1008, Accuracy: 2853/64110 (8.10%)\n",
            "highest_accuracy:61.85% \n",
            " current lr:  0.0009999663790013797\n",
            "epoch:7,train_loss:1.0987\n",
            "Validation set: Weighted loss: 1.0998, Accuracy: 5259/64110 (14.91%)\n",
            "highest_accuracy:61.85% \n",
            " current lr:  0.00010003362099862035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3fuweSvcGCoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGZhzMyjtaDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TEST**"
      ]
    },
    {
      "metadata": {
        "id": "36u1WP9UtYkp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "#from model import *\n",
        "#from dataset import TitleDataset, Toidx\n",
        "#from preprocess import preprocess_, make_new_data\n",
        "\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "\n",
        "# _ = preprocess_()\n",
        "\n",
        "\n",
        "with open(data_dir + 'save/word_to_ix_en.pickle', mode='rb') as f:\n",
        "     word_to_ix_en = pickle.load(f)\n",
        "with open(data_dir + 'save/word_to_ix_zh.pickle', mode='rb') as f:\n",
        "     word_to_ix_zh = pickle.load(f)\n",
        "with open(data_dir + 'save/train_df.pickle', mode='rb') as f:\n",
        "     train_df = pickle.load(f)\n",
        "with open(data_dir + 'save/test_df.pickle', mode='rb') as f:\n",
        "     test_df = pickle.load(f)\n",
        "\n",
        "#_,given_dic,fixed_dic,forecast_dic = make_new_data(train_df)\n",
        "\n",
        "with open(data_dir + 'save/fixed_dic.pickle', mode='rb') as f:\n",
        "    fixed_dic = pickle.load(f)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 128\n",
        "max_seq_en = 50\n",
        "max_seq_zh = 100\n",
        "\n",
        "model = LSTM_Classifier(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), target_size=3, seq_length=max_seq_length)\n",
        "#model = MLP_Classifier(EMBEDDING_DIM, len(word_to_ix), target_size=3, seq_length=max_seq_length)\n",
        "#model = Twolang_Classifier(EMBEDDING_DIM, len(word_to_ix_en),len(word_to_ix_zh), target_size=3)\n",
        "\n",
        "title1_en_test = list(test_df[\"title1_en\"])\n",
        "title2_en_test = list(test_df[\"title2_en\"])\n",
        "title1_zh_test = list(test_df[\"title1_zh\"])\n",
        "title2_zh_test = list(test_df[\"title2_zh\"])\n",
        "test_tid1 = list(test_df[\"tid1\"])\n",
        "test_tid2 = list(test_df[\"tid2\"])\n",
        "\n",
        "id_ = test_df[\"id\"]\n",
        "\n",
        "\n",
        "preded_id_label = []\n",
        "\n",
        "given, not_given = 0, 0\n",
        "\n",
        "agree_dic = defaultdict(list)\n",
        "disagree_dic = defaultdict(list)\n",
        "\n",
        "for id1, id_label_list in fixed_dic.items():\n",
        "    if len(id_label_list) == 0:\n",
        "        continue\n",
        "    id_list = np.array(id_label_list)[:,0]\n",
        "    label_list = np.array(id_label_list)[:,1]\n",
        "    for id2, label in zip(id_list, label_list):\n",
        "\n",
        "        if label == 1:\n",
        "            agree_dic[id1].append(id2)\n",
        "        elif label == 2:\n",
        "            disagree_dic[id1].append(id2)\n",
        "\n",
        "\n",
        "change=0\n",
        "while True:\n",
        "    for tid1, agree_id_list in agree_dic.items():\n",
        "        for tid2 in agree_id_list:\n",
        "            disagree_to_tid2 = disagree_dic[tid2]\n",
        "            for dis in disagree_to_tid2:\n",
        "                if not dis in disagree_dic[tid1]:\n",
        "                    disagree_dic[tid1].append(dis)\n",
        "                    change+=1\n",
        "\n",
        "                if not tid1 in disagree_dic[dis]:\n",
        "                    disagree_dic[dis].append(tid1)\n",
        "                    change+=1\n",
        "\n",
        "            agree_to_tid2 = agree_dic[tid2]\n",
        "            for dis in agree_to_tid2:\n",
        "                if not dis in agree_dic[tid1]:\n",
        "                    agree_dic[tid1].append(dis)\n",
        "                    change+=1\n",
        "\n",
        "                if not tid1 in agree_dic[dis]:\n",
        "                    agree_dic[dis].append(tid1)\n",
        "                    change+=1\n",
        "    for tid1, disagree_id_list in disagree_dic.items():\n",
        "        for tid2 in disagree_id_list:\n",
        "\n",
        "            agree_to_tid2 = agree_dic[tid2]\n",
        "            for dis in agree_to_tid2:\n",
        "                if not dis in disagree_dic[tid1]:\n",
        "                    disagree_dic[tid1].append(dis)\n",
        "                    change+=1\n",
        "\n",
        "                if not tid1 in disagree_dic[dis]:\n",
        "                    disagree_dic[dis].append(tid1)\n",
        "                    change+=1\n",
        "\n",
        "    print(\"change number: \", change)\n",
        "    if change == 0:\n",
        "        break\n",
        "    else:\n",
        "        change = 0\n",
        "\n",
        "mujun = 0\n",
        "\n",
        "for id1, id2, each_id in zip(test_tid1, test_tid2, id_):\n",
        "    if id2 in disagree_dic[id1]:\n",
        "        #check\n",
        "        if id1 in disagree_dic[id2]:\n",
        "            preded_id_label.append((each_id, 2))\n",
        "        else:\n",
        "            mujun+=1\n",
        "\n",
        "    elif id2 in agree_dic[id1]:\n",
        "        #check\n",
        "        if id1 in agree_dic[id2]:\n",
        "            preded_id_label.append((each_id, 1))\n",
        "        else:\n",
        "            mujun+=1\n",
        "\n",
        "\n",
        "preded_id_label = []\n",
        "print(\"What could be predicted:{}, Contradiction:{}, total:{}\".format(len(preded_id_label), mujun, len(test_df)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# for id1, id2, each_id in zip(test_tid1, test_tid2, id_):\n",
        "#     if not id1 in forecast_dic.keys():\n",
        "#         #print(\"label cannot be predicted\")\n",
        "#         not_given+=1\n",
        "#         pass\n",
        "#     else:\n",
        "#         forecast_data_label = np.array(forecast_dic[id1])\n",
        "#         if len(forecast_data_label) == 0:\n",
        "#             continue\n",
        "#\n",
        "#         forecast_id = forecast_data_label[:,0]\n",
        "#         forecast_label = forecast_data_label[:,1]\n",
        "#\n",
        "#         if id2 in forecast_id:\n",
        "#             idx = list(forecast_id).index(id2)\n",
        "#             label = forecast_label[idx]\n",
        "#              given+=1\n",
        "#             # preded_id_label.append((each_id, label))\n",
        "#         else:\n",
        "#             #print(\"label not given\")\n",
        "#             not_given+=1\n",
        "#             pass\n",
        "# print(\"予測可能セット:{}, わからないセット:{}\".format(given, not_given))\n",
        "\n",
        "\n",
        "PATH = data_dir+ \"model/MLP.model\"\n",
        "PATH_list = [data_dir + \"model/{}fold_mlp.model\".format(fold) for fold in range(1,6,1)]\n",
        "\n",
        "\n",
        "average_prediction = []\n",
        "for PATH in PATH_list:\n",
        "\n",
        "    model = torch.load(PATH)\n",
        "    print(\"model loaded:{}\".format(PATH))\n",
        "\n",
        "\n",
        "    # test dataset. label is None.\n",
        "    test_dataset = TitleDataset(title1_en_test, title2_en_test, title1_zh_test, title2_zh_test, None,\n",
        "                                dic_en=word_to_ix_en, dic_zh=word_to_ix_zh, transform=Toidx(),\n",
        "                                seq_length_en=max_seq_en, seq_length_zh=max_seq_zh, if_test=True)\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        for batch_idx, sample_batch in enumerate(tqdm(test_loader)):\n",
        "            en_title1 = sample_batch[\"t1_en\"].to(device)\n",
        "            en_title2 = sample_batch[\"t2_en\"].to(device)\n",
        "            zh_title1 = sample_batch[\"t1_zh\"].to(device)\n",
        "            zh_title2 = sample_batch[\"t2_zh\"].to(device)\n",
        "            output = model(en_title1, en_title2, zh_title1, zh_title2)\n",
        "\n",
        "            # pred = output.max(1, keepdim=True)[1].cpu()\n",
        "            #print(\"model out :\",output.size())\n",
        "            #predictions.extend(list(pred.numpy()))\n",
        "            output = output.cpu().numpy()\n",
        "            #print(\"model out:\",output.shape)\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                predictions = output\n",
        "            else:\n",
        "                predictions = np.vstack((predictions, output))\n",
        "\n",
        "    average_prediction.append(predictions)\n",
        "\n",
        "average_prediction = np.array(average_prediction)\n",
        "# print(\"total pred:\", average_prediction.shape)\n",
        "average_prediction = np.mean(average_prediction, axis=0)\n",
        "# print(\"total pred:\", average_prediction.shape)\n",
        "\n",
        "predictions = np.argmax(average_prediction, axis=1)\n",
        "print(\"predictions:\", predictions.shape)\n",
        "\n",
        "#'unrelated', 0\n",
        "#'agreed', 1\n",
        "#'disagreed', 2\n",
        "\n",
        "\n",
        "if len(preded_id_label) == 0:\n",
        "    preded_labels = []\n",
        "    preded_id = []\n",
        "else:\n",
        "    preded_id = np.array(preded_id_label)[:, 0]\n",
        "    preded_labels = np.array(preded_id_label)[:, 1]\n",
        "print(\"directly preded label:\", len(preded_id))\n",
        "\n",
        "\n",
        "fixed_predictions = []\n",
        "for each_id, p in zip(id_, predictions):\n",
        "    if each_id in preded_id:\n",
        "        idx = list(preded_id).index(each_id)\n",
        "        fixed_predictions.append(preded_labels[idx])\n",
        "    else:\n",
        "        fixed_predictions.append(p)\n",
        "\n",
        "\n",
        "new_predictions = []\n",
        "for p in fixed_predictions:\n",
        "    if p == 0:\n",
        "        new_predictions.append(\"unrelated\")\n",
        "    elif p==1:\n",
        "        new_predictions.append(\"agreed\")\n",
        "    elif p==2:\n",
        "        new_predictions.append(\"disagreed\")\n",
        "\n",
        "\n",
        "#\n",
        "# c = Counter(list(predictions))\n",
        "# print(\"original\",c)\n",
        "#\n",
        "# c = Counter(fixed_predictions)\n",
        "# print(\"fixed\", c)\n",
        "\n",
        "\n",
        "submit_csv = pd.concat([id_, pd.Series(new_predictions)], axis=1)\n",
        "#display(submit_csv)\n",
        "\n",
        "submit_csv.columns = [\"Id\", \"Category\"]\n",
        "submit_csv.to_csv(data_dir + \"submit.csv\", header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfVRZQq5wSTo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submit_csv.to_csv(data_dir + \"submit.csv\", header=True, index=False)\n",
        "submit = pd.read_csv(\"submit.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHkGc1SPAKC8",
        "colab_type": "code",
        "outputId": "82476bdd-0975-4704-b72f-578ac35a08e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "search = \"1000人犯罪团伙来德州偷孩子取器官,男子散播“1000人来德州偷孩子挖器官”谣言\"\n",
        "\n",
        "r = requests.get(\"https://www.google.com/search\", params={'q':search})\n",
        "\n",
        "soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "res = soup.find(\"div\", {\"id\": \"resultStats\"})\n",
        "print (res.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "About 8 results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a0shaFITMFvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TRAIN CHINESE BERT**"
      ]
    },
    {
      "metadata": {
        "id": "0FPW_QpfJql6",
        "colab_type": "code",
        "outputId": "79f64717-be28-435a-8d94-32a37088081b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3702
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "import copy\n",
        "# from model import BERT_Classifier\n",
        "#from dataset import *\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import requests\n",
        "\n",
        "class BERT_Classifier(nn.Module):\n",
        "    def __init__(self, bert_model, target_size=3):\n",
        "        super(BERT_Classifier, self).__init__()\n",
        "\n",
        "        self.embedding_dim=768\n",
        "        kernel_num=256\n",
        "        self.seq_length_en=100\n",
        "\n",
        "        self.bert_model = bert_model\n",
        "        # self.conv2_en = nn.Conv2d(1, kernel_num, (2, self.embedding_dim))\n",
        "        # self.conv3_en = nn.Conv2d(1, kernel_num, (3, self.embedding_dim))\n",
        "        # self.conv4_en = nn.Conv2d(1, kernel_num, (4, self.embedding_dim))\n",
        "        # self.Max2_pool_en = nn.MaxPool2d((self.seq_length_en-2+1, 1))\n",
        "        # self.Max3_pool_en = nn.MaxPool2d((self.seq_length_en-3+1, 1))\n",
        "        # self.Max4_pool_en = nn.MaxPool2d((self.seq_length_en-4+1, 1))\n",
        "\n",
        "\n",
        "        # self.fc1 = nn.Linear(kernel_num*3, 300)\n",
        "        # self.fc1_bn = nn.BatchNorm1d(300)\n",
        "        # self.fc1_drop = nn.Dropout(p=0.3, inplace=False)\n",
        "        # self.fc2 = nn.Linear(300, target_size)\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 768)\n",
        "        #self.fc1_bn = nn.BatchNorm1d(300)\n",
        "        self.fc1_drop = nn.Dropout(p=0.3, inplace=False)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(768, target_size)\n",
        "\n",
        "    def forward(self, input_ids, input_mask):\n",
        "        batch = len(input_ids)\n",
        "\n",
        "        last_encoder_layer, _ = self.bert_model(input_ids, token_type_ids=None, attention_mask=input_mask, output_all_encoded_layers=False)\n",
        "\n",
        "        # last_encoder_layer = last_encoder_layer.view(batch, 1, self.seq_length_en, self.embedding_dim)\n",
        "        #\n",
        "        #\n",
        "        # conv2 = F.relu(self.conv2_en(last_encoder_layer))\n",
        "        # conv3 = F.relu(self.conv3_en(last_encoder_layer))\n",
        "        # conv4 = F.relu(self.conv4_en(last_encoder_layer))\n",
        "        #\n",
        "        # pool2 = self.Max2_pool_en(conv2).view(batch, -1)\n",
        "        # pool3 = self.Max3_pool_en(conv3).view(batch, -1)\n",
        "        # pool4 = self.Max4_pool_en(conv4).view(batch, -1)\n",
        "\n",
        "        #print(last_encoder_layer.size())\n",
        "        # embedding = torch.sum(last_encoder_layer, 1)\n",
        "\n",
        "        #cat = torch.cat((pool2, pool3, pool4), dim=1)\n",
        "\n",
        "        #print(\"fc1\", cat.size())\n",
        "\n",
        "        first_token_tensor = last_encoder_layer[:, 0]\n",
        "\n",
        "        # fc1 = self.fc1_drop(F.relu(self.fc1(first_token_tensor)))\n",
        "        fc1 = self.fc1_drop(self.activation(self.fc1(first_token_tensor)))\n",
        "        fc2 = self.fc2(fc1)\n",
        "\n",
        "        return fc2\n",
        " \n",
        "\n",
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 256\n",
        "max_seq_en = 50\n",
        "max_seq_zh = 60\n",
        "EPOCH= 5\n",
        "\n",
        "batch=64\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\",device)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(data_dir + \"train.csv\")\n",
        "# test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "train_df.replace('unrelated', 0, inplace=True)\n",
        "train_df.replace('agreed', 1, inplace=True)\n",
        "train_df.replace('disagreed', 2, inplace=True)\n",
        "\n",
        "\n",
        "def chinese_clean_series(series):\n",
        "    def clean_seq(seq):\n",
        "        seq = str(seq)\n",
        "        ori = copy.copy(seq)\n",
        "\n",
        "        seq = seq.replace(\"< i >\", \"\")\n",
        "        seq = seq.replace(\"< / i >\", \"\")\n",
        "        seq = seq.replace(\"\\n\", \"\")\n",
        "        seq = re.sub(r'[,.\"''“”。、#()→⇒←↓↑:;_㊙️【《》=|/<>]+', '', seq)\n",
        "        seq = re.sub(r'[!！？?-]+', ' ', seq)\n",
        "        seq = re.sub(r'[$]+', '$ ', seq)\n",
        "        seq = re.sub(r'[0-9]+', '<NUM>', seq)\n",
        "\n",
        "        if len(seq)==0:\n",
        "            print(\"0 lengrh assert!!,\",ori, seq)\n",
        "\n",
        "        return seq\n",
        "\n",
        "    series = series.apply(clean_seq)\n",
        "    return series\n",
        "\n",
        "\n",
        "\n",
        "train_df[\"title1_zh\"] =  chinese_clean_series(train_df[\"title1_zh\"])\n",
        "train_df[\"title2_zh\"] =  chinese_clean_series(train_df[\"title2_zh\"])\n",
        "\n",
        "\n",
        "train_df = train_df.sample(frac=1, random_state=0).reset_index(drop=True)#.iloc[:300, :]\n",
        "\n",
        "\n",
        "# K-Fold Cross validation\n",
        "fold_num = 5\n",
        "kf = KFold(n_splits=fold_num , random_state = 42)\n",
        "kf.get_n_splits(train_df)\n",
        "\n",
        "# kf.get_n_splits(X, y)\n",
        "\n",
        "train_data_list = []\n",
        "val_data_list = []\n",
        "for train_index, val_index in kf.split(train_df):\n",
        "#for train_index, val_index in kf.split(X):\n",
        "    training_df = train_df.iloc[train_index]\n",
        "    val_df = train_df.iloc[val_index]\n",
        "\n",
        "\n",
        "\n",
        "    train1_en, train2_en = list(training_df[\"title1_en\"]), list(training_df[\"title2_en\"])\n",
        "    train1_zh, train2_zh = list(training_df[\"title1_zh\"]), list(training_df[\"title2_zh\"])\n",
        "\n",
        "    y_train = list(training_df[\"label\"])\n",
        "\n",
        "    val1_en, val2_en = list(val_df[\"title1_en\"]), list(val_df[\"title2_en\"])\n",
        "    val1_zh, val2_zh = list(val_df[\"title1_zh\"]), list(val_df[\"title2_zh\"])\n",
        "    y_val = list(val_df[\"label\"])\n",
        "\n",
        "\n",
        "    train_data_list.append((train1_zh,train2_zh, y_train))#train1_zh,train2_zh,y_train))\n",
        "    val_data_list.append((val1_zh, val2_zh, y_val))# val1_zh, val2_zh,y_val))\n",
        "#\n",
        "# with open('save/kfold_train_data.pickle', mode='wb') as f:\n",
        "#     pickle.dump(train_data_list, f)\n",
        "# with open('save/kfold_val_data.pickle', mode='wb') as f:\n",
        "#     pickle.dump(val_data_list, f)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "bert_model = BertModel.from_pretrained('bert-base-chinese').to(device)\n",
        "bert_model.eval()\n",
        "\n",
        "fold=1\n",
        "for train_fold, val_fold in zip(train_data_list,val_data_list):\n",
        "    print(\"{}/{} fold :\".format(fold, fold_num))\n",
        "    print(\"train length:{}, val length:{}\".format(len(train_fold[0]), len(val_fold[0])))\n",
        "\n",
        "    (train1_en,train2_en,y_train) = train_fold\n",
        "    (val1_en, val2_en,y_val) = val_fold\n",
        "\n",
        "    c = Counter(y_train)\n",
        "    class_weight = []\n",
        "    for label, num in sorted(c.items()):\n",
        "        print(label, num)\n",
        "        class_weight.append(len(y_train)/(3*num))\n",
        "    class_weight = torch.FloatTensor(class_weight).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model = BERT_Classifier(bert_model)\n",
        "    model.to(device)\n",
        "    loss_function = nn.CrossEntropyLoss()#weight=class_weight)\n",
        "    weighted_loss_function = nn.CrossEntropyLoss(weight=class_weight)#weight=class_weight)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = BERTDataset(train1_zh, train2_zh, y_train, tokenizer, seq_length=max_seq_zh)\n",
        "    val_dataset = BERTDataset(val1_zh, val2_zh, y_val, tokenizer, seq_length=max_seq_zh)\n",
        "\n",
        "    class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in y_train])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weight = samples_weight.double()\n",
        "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=False, sampler=sampler)#, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
        "    \n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = CosineAnnealingLR(optimizer, len(train_loader), eta_min = 0.001/10)\n",
        "\n",
        "    def train(epoch):\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, sample_batch in enumerate(tqdm(train_loader)):\n",
        "            input_ids = sample_batch[\"input_ids\"].to(device)\n",
        "            input_mask = sample_batch[\"input_mask\"].to(device)\n",
        "            input_type_ids = sample_batch[\"input_type_ids\"].to(device)\n",
        "            y = sample_batch[\"label\"].to(device)\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, input_mask)\n",
        "\n",
        "            loss = loss_function(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx%100==0:\n",
        "                print(\"epoch:{},train_loss:{:.4f}\".format(epoch+1 ,loss))\n",
        "\n",
        "\n",
        "        print(\"epoch:{},train_loss:{:.4f}\".format(epoch+1 ,loss)) \n",
        "\n",
        "        #print(\"train data all :\", (batch_idx+1)*batch)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def test():\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "\n",
        "            for batch_idx, sample_batch in enumerate(val_loader):\n",
        "                input_ids = sample_batch[\"input_ids\"].to(device)\n",
        "                input_mask = sample_batch[\"input_mask\"].to(device)\n",
        "                input_type_ids = sample_batch[\"input_type_ids\"].to(device)\n",
        "                y = sample_batch[\"label\"].to(device)\n",
        "\n",
        "                output = model(input_ids, input_mask)\n",
        "                # sum up batch loss\n",
        "                #test_loss += weighted_loss_function(output, y).item()\n",
        "                test_loss += loss_function(output, y).item()\n",
        "                # get the index of the max log-probability\n",
        "                pred = output.max(1, keepdim=True)[1]\n",
        "                correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "            #test_loss /= len(val_loader.dataset)\n",
        "            test_loss /= batch_idx+1\n",
        "            #accuracy = 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "            accuracy = weighted_accuracy(pred, y)\n",
        "\n",
        "            print('Validation set: Weighted loss: {:.4f}, Weighted Accuracy: {}/{} ({:.2f}%)'\n",
        "                  .format(test_loss, correct, len(val_loader.dataset),\n",
        "                          accuracy))\n",
        "\n",
        "            return test_loss, accuracy\n",
        "\n",
        "\n",
        "    def weighted_accuracy(pred, true):\n",
        "        true = true.cpu().numpy()\n",
        "        pred = pred.cpu().numpy()\n",
        "\n",
        "        class_weight = [1/16, 1/15, 1/5]\n",
        "        score = 0\n",
        "        perfect_score = 0\n",
        "\n",
        "        for p, t in zip(pred, true):\n",
        "            if p == t:\n",
        "                if t == 0:\n",
        "                    score += 1/16\n",
        "                    perfect_score += 1/16\n",
        "                elif t == 1:\n",
        "                    score += 1/15\n",
        "                    perfect_score += 1/15\n",
        "                elif t == 2:\n",
        "                    score += 1/5\n",
        "                    perfect_score += 1/5\n",
        "            else:\n",
        "                if t == 0:\n",
        "                    perfect_score += 1/16\n",
        "                elif t == 1:\n",
        "                    perfect_score += 1/15\n",
        "                elif t == 2:\n",
        "                    perfect_score += 1/5\n",
        "        #print(\"score:{}, ideal:{}\".format(score, perfect_score))\n",
        "        return 100 * score/perfect_score\n",
        "\n",
        "    def save_model(model, val_accuracy, save_path=data_dir + 'model'):\n",
        "    # if os.path.exists(path + \"*.model\"):\n",
        "    #     os.remove(path + \"*.model\")\n",
        "        name = \"{}fold_mlp.model\".format(fold)\n",
        "        PATH = os.path.join(save_path, name)\n",
        "        torch.save(model, PATH)\n",
        "\n",
        "    lowest_loss = 1000000000\n",
        "    highest_accuracy = 0\n",
        "    for epoch in range(EPOCH):\n",
        "        #print(epoch+1)\n",
        "        model = train(epoch)\n",
        "        val_loss, accuracy = test()\n",
        "\n",
        "    #     if val_loss < lowest_loss:\n",
        "    #         lowest_loss = val_loss\n",
        "    #         save_model(model)\n",
        "\n",
        "        if accuracy > highest_accuracy:\n",
        "            #print(\"saving model...\")\n",
        "            highest_accuracy = accuracy\n",
        "            save_model(model, highest_accuracy)\n",
        "        print(\"highest_accuracy:{:.2f}% \\n\".format(highest_accuracy))\n",
        "\n",
        "    fold+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.62)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.62 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.62)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.62->boto3->pytorch_pretrained_bert) (1.11.0)\n",
            "device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12/10/2018 09:24:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /root/.pytorch_pretrained_bert/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
            "12/10/2018 09:24:31 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /root/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f\n",
            "12/10/2018 09:24:31 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmp9xresmxm\n",
            "12/10/2018 09:24:36 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n",
            "  0%|          | 0/4007 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/5 fold :\n",
            "train length:256441, val length:64111\n",
            "0 175383\n",
            "1 74459\n",
            "2 6599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/4007 [00:01<1:50:37,  1.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 101/4007 [02:18<1:29:33,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 201/4007 [04:36<1:27:27,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 301/4007 [06:53<1:24:58,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 401/4007 [09:10<1:22:54,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 501/4007 [11:27<1:20:23,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 601/4007 [13:45<1:18:22,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 701/4007 [16:02<1:15:59,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 801/4007 [18:20<1:13:23,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 901/4007 [20:37<1:11:10,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 1001/4007 [22:54<1:08:56,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1101/4007 [25:12<1:06:37,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 1201/4007 [27:29<1:04:35,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1301/4007 [29:46<1:01:59,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 1401/4007 [32:04<59:44,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1501/4007 [34:21<57:27,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 1601/4007 [36:38<55:12,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1701/4007 [38:55<52:53,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 1801/4007 [41:13<50:42,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 1901/4007 [43:30<48:17,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 2001/4007 [45:47<45:59,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 2101/4007 [48:05<43:44,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 2201/4007 [50:22<41:32,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 2301/4007 [52:39<39:08,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 2401/4007 [54:57<36:51,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 2501/4007 [57:14<34:28,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 2601/4007 [59:31<32:20,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2701/4007 [1:01:49<29:56,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 2801/4007 [1:04:06<27:39,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 2901/4007 [1:06:23<25:20,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 3001/4007 [1:08:41<23:06,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 3101/4007 [1:10:58<20:48,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 3201/4007 [1:13:15<18:30,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 3301/4007 [1:15:32<16:11,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 3401/4007 [1:17:50<13:53,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 3501/4007 [1:20:07<11:34,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 3601/4007 [1:22:25<09:18,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 3701/4007 [1:24:42<07:01,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 3801/4007 [1:26:59<04:43,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 3901/4007 [1:29:17<02:26,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.1007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 4001/4007 [1:31:34<00:08,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4007/4007 [1:31:42<00:00,  1.33s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:1,train_loss:1.0978\n",
            "Validation set: Weighted loss: 1.1028, Weighted Accuracy: 1667/64110 (12.44%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type BERT_Classifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "  0%|          | 0/4007 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "highest_accuracy:12.44% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/4007 [00:01<1:47:03,  1.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 101/4007 [02:19<1:29:46,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 201/4007 [04:36<1:27:29,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 301/4007 [06:53<1:25:01,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 401/4007 [09:11<1:22:31,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 501/4007 [11:28<1:20:24,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 601/4007 [13:45<1:18:04,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 701/4007 [16:03<1:16:02,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 801/4007 [18:20<1:13:44,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 901/4007 [20:37<1:11:12,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 1001/4007 [22:55<1:08:58,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1101/4007 [25:12<1:06:45,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 1201/4007 [27:29<1:04:16,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1301/4007 [29:47<1:02:06,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 1401/4007 [32:04<59:46,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1501/4007 [34:22<57:43,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 1601/4007 [36:39<55:21,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1701/4007 [38:56<52:51,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 1801/4007 [41:14<50:38,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 1901/4007 [43:31<48:19,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 2001/4007 [45:48<46:03,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 2101/4007 [48:06<43:42,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 2201/4007 [50:23<41:28,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 2301/4007 [52:41<39:09,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 2401/4007 [54:58<36:50,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 2501/4007 [57:15<34:31,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 2601/4007 [59:33<32:15,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2701/4007 [1:01:50<29:56,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 2801/4007 [1:04:08<27:40,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 2901/4007 [1:06:26<25:26,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 3001/4007 [1:08:43<23:08,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 3101/4007 [1:11:01<20:44,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 3201/4007 [1:13:18<18:33,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 3301/4007 [1:15:36<16:14,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 3401/4007 [1:17:53<13:54,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 3501/4007 [1:20:11<11:36,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 3601/4007 [1:22:28<09:19,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 3701/4007 [1:24:46<07:02,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 3801/4007 [1:27:03<04:44,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 3901/4007 [1:29:21<02:26,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.1005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 4001/4007 [1:31:39<00:08,  1.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.0934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4007/4007 [1:31:47<00:00,  1.34s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:2,train_loss:1.4589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4007 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set: Weighted loss: 1.1338, Weighted Accuracy: 1667/64110 (12.44%)\n",
            "highest_accuracy:12.44% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/4007 [00:01<1:43:04,  1.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 101/4007 [02:18<1:29:34,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 201/4007 [04:36<1:27:15,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 301/4007 [06:53<1:24:54,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 401/4007 [09:11<1:22:43,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 501/4007 [11:28<1:20:27,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 601/4007 [13:46<1:18:06,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 701/4007 [16:03<1:16:00,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 801/4007 [18:21<1:13:59,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 901/4007 [20:38<1:11:21,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 1001/4007 [22:56<1:09:05,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 1101/4007 [25:13<1:06:36,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 1201/4007 [27:31<1:04:24,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1301/4007 [29:48<1:02:07,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 1401/4007 [32:05<59:45,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 1501/4007 [34:23<57:28,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 1601/4007 [36:40<55:13,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 1701/4007 [38:58<52:56,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 1801/4007 [41:15<50:35,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 1901/4007 [43:33<48:21,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 2001/4007 [45:50<46:04,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 2101/4007 [48:07<43:51,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 2201/4007 [50:25<41:25,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 2301/4007 [52:42<39:13,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 2401/4007 [55:00<36:52,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 2501/4007 [57:17<34:35,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 2601/4007 [59:35<32:18,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2701/4007 [1:01:53<29:59,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 2801/4007 [1:04:11<27:43,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 2901/4007 [1:06:28<25:26,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.1025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 3001/4007 [1:08:46<23:03,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 3101/4007 [1:11:03<20:47,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 3201/4007 [1:13:21<18:31,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 3301/4007 [1:15:38<16:12,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 3401/4007 [1:17:56<13:57,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 3501/4007 [1:20:13<11:37,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 3601/4007 [1:22:31<09:21,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 3701/4007 [1:24:49<07:02,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 3801/4007 [1:27:06<04:44,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 3901/4007 [1:29:24<02:26,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:3,train_loss:1.0999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 3969/4007 [1:30:57<00:52,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b5be95c70f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m#print(epoch+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b5be95c70f3f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0JZBCFAUYbRF",
        "colab_type": "code",
        "outputId": "6a8666af-b543-42b3-abb1-25c16fd0e20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.1 GB  | Proc size: 3.0 GB\n",
            "GPU RAM Free: 10721MB | Used: 720MB | Util   6% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jYwZbK2ceSwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "# from model import BERT_Classifier\n",
        "from dataset import *\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "\n",
        "\n",
        "class BERT_Classifier(nn.Module):\n",
        "    def __init__(self,target_size=3):\n",
        "        super(BERT_Classifier, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(768, 768)\n",
        "        self.fc1_bn = nn.BatchNorm1d(768)\n",
        "        self.fc1_drop = nn.Dropout(p=0.3, inplace=False)\n",
        "        self.fc2 = nn.Linear(768, target_size)\n",
        "\n",
        "    def forward(self, last_encoder_layer):#, input_ids, input_mask):\n",
        "\n",
        "        #last_encoder_layer, _ = self.bert_model(input_ids, token_type_ids=None, attention_mask=input_mask, output_all_encoded_layers=False)\n",
        "\n",
        "\n",
        "        #print(last_encoder_layer.size())\n",
        "        embedding = torch.sum(last_encoder_layer, 1)\n",
        "        #print(\"embedding\", embedding.size())\n",
        "\n",
        "        fc1 = self.fc1_drop(F.relu(self.fc1_bn(self.fc1(embedding))))\n",
        "        fc2 = self.fc2(fc1)\n",
        "\n",
        "        return fc2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 256\n",
        "max_seq_en = 50\n",
        "max_seq_zh = 100\n",
        "EPOCH=10\n",
        "\n",
        "batch=32\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\",device)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "\n",
        "train_df.replace('unrelated', 0, inplace=True)\n",
        "train_df.replace('agreed', 1, inplace=True)\n",
        "train_df.replace('disagreed', 2, inplace=True)\n",
        "\n",
        "\n",
        "X = pd.read_pickle(\"save/features.pickle\")\n",
        "print(\"X:\", X.shape)\n",
        "y = list(train_df[\"label\"])\n",
        "\n",
        "\n",
        "p = list(zip(X, y))\n",
        "random.shuffle(p)\n",
        "X, y = zip(*p)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "# K-Fold Cross validation\n",
        "fold_num = 5\n",
        "kf = KFold(n_splits=fold_num)\n",
        "kf.get_n_splits(X, y)\n",
        "\n",
        "train_data_list = []\n",
        "val_data_list = []\n",
        "fold=1\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train = X[train_index]\n",
        "    X_val = X[val_index]\n",
        "    y_train = y[train_index]\n",
        "    y_val = y[val_index]\n",
        "\n",
        "\n",
        "    print(\"{}/{} fold :\".format(fold, fold_num))\n",
        "    print(\"train length:{}, val length:{}\".format(len(X_train), len(X_val)))\n",
        "\n",
        "\n",
        "    c = Counter(y_train)\n",
        "    class_weight = []\n",
        "    for label, num in sorted(c.items()):\n",
        "        print(label, num)\n",
        "        class_weight.append(len(y_train)/(3*num))\n",
        "    class_weight = torch.FloatTensor(class_weight).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model = BERT_Classifier()\n",
        "    model.to(device)\n",
        "    loss_function = nn.CrossEntropyLoss()#weight=class_weight)\n",
        "    weighted_loss_function = nn.CrossEntropyLoss(weight=class_weight)#weight=class_weight)\n",
        "\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "    val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "\n",
        "    #ミニバッチ内のクラス比を揃える.\n",
        "    class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in y_train])\n",
        "    samples_weight = torch.from_numpy(samples_weight)\n",
        "    samples_weight = samples_weight.double()\n",
        "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=False, sampler=sampler)#, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    def train(epoch):\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, sample_batch in enumerate(tqdm(train_loader)):\n",
        "            inputs, y = sample_batch\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = loss_function(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"epoch:{},train_loss:{:.4f}\".format(epoch+1 ,loss))\n",
        "        #print(\"train data all :\", (batch_idx+1)*batch)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def test():\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "\n",
        "            for batch_idx, sample_batch in enumerate(val_loader):\n",
        "                inputs, y = sample_batch\n",
        "                inputs = inputs.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "\n",
        "                output = model(inputs)\n",
        "                # sum up batch loss\n",
        "                test_loss += weighted_loss_function(output, y).item()\n",
        "                # get the index of the max log-probability\n",
        "                pred = output.max(1, keepdim=True)[1]\n",
        "                correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "            #test_loss /= len(val_loader.dataset)\n",
        "            test_loss /= batch_idx+1\n",
        "            #accuracy = 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "            accuracy = weighted_accuracy(pred, y)\n",
        "\n",
        "            print('Validation set: Weighted loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'\n",
        "                  .format(test_loss, correct, len(val_loader.dataset),\n",
        "                          accuracy))\n",
        "\n",
        "            return test_loss, accuracy\n",
        "\n",
        "\n",
        "    def weighted_accuracy(pred, true):\n",
        "        true = true.cpu().numpy()\n",
        "        pred = pred.cpu().numpy()\n",
        "\n",
        "        class_weight = [1/16, 1/15, 1/5]\n",
        "        score = 0\n",
        "        perfect_score = 0\n",
        "\n",
        "        for p, t in zip(true, pred):\n",
        "            if p == t:\n",
        "                if t == 0:\n",
        "                    score += 1/16\n",
        "                    perfect_score += 1/16\n",
        "                elif t == 1:\n",
        "                    score += 1/15\n",
        "                    perfect_score += 1/15\n",
        "                elif t == 2:\n",
        "                    score += 1/5\n",
        "                    perfect_score += 1/5\n",
        "            else:\n",
        "                if t == 0:\n",
        "                    perfect_score += 1/16\n",
        "                elif t == 1:\n",
        "                    perfect_score += 1/15\n",
        "                elif t == 2:\n",
        "                    perfect_score += 1/5\n",
        "        #print(\"score:{}, ideal:{}\".format(score, perfect_score))\n",
        "        return 100 * score/perfect_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save_model(model, val_accuracy, save_path=\"model/BERT/\"):\n",
        "        # if os.path.exists(path + \"*.model\"):\n",
        "        #     os.remove(path + \"*.model\")\n",
        "        name = \"{}fold_mlp.model\".format(fold)\n",
        "        PATH = os.path.join(save_path, name)\n",
        "        torch.save(model, PATH)\n",
        "\n",
        "    lowest_loss = 1000000000\n",
        "    highest_accuracy = 0\n",
        "    for epoch in range(EPOCH):\n",
        "        #print(epoch+1)\n",
        "        model = train(epoch)\n",
        "        val_loss, accuracy = test()\n",
        "\n",
        "    #     if val_loss < lowest_loss:\n",
        "    #         lowest_loss = val_loss\n",
        "    #         save_model(model)\n",
        "\n",
        "        if accuracy > highest_accuracy:\n",
        "            #print(\"saving model...\")\n",
        "            highest_accuracy = accuracy\n",
        "            #save_model(model, highest_accuracy)\n",
        "        print(\"highest_accuracy:{:.2f}% \\n\".format(highest_accuracy))\n",
        "\n",
        "    fold+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}