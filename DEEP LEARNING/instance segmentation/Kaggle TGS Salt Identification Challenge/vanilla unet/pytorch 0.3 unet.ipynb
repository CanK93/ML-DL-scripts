{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "7d7bc35bfdb4aa0dbb83ad76872ffb50446c5295"
   },
   "outputs": [],
   "source": [
    "directory = '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            ConvRelu(in_channels, middle_channels),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNet11(nn.Module):\n",
    "    def __init__(self, num_filters=32):\n",
    "        \"\"\"\n",
    "        :param num_classes:\n",
    "        :param num_filters:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Convolutions are from VGG11\n",
    "        self.encoder = models.vgg11().features\n",
    "        \n",
    "        # \"relu\" layer is taken from VGG probably for generality, but it's not clear \n",
    "        self.relu = self.encoder[1]\n",
    "        \n",
    "        self.conv1 = self.encoder[0]\n",
    "        self.conv2 = self.encoder[3]\n",
    "        self.conv3s = self.encoder[6]\n",
    "        self.conv3 = self.encoder[8]\n",
    "        self.conv4s = self.encoder[11]\n",
    "        self.conv4 = self.encoder[13]\n",
    "        self.conv5s = self.encoder[16]\n",
    "        self.conv5 = self.encoder[18]\n",
    "\n",
    "        self.center = DecoderBlock(num_filters * 8 * 2, num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec5 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec4 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 4)\n",
    "        self.dec3 = DecoderBlock(num_filters * (8 + 4), num_filters * 4 * 2, num_filters * 2)\n",
    "        self.dec2 = DecoderBlock(num_filters * (4 + 2), num_filters * 2 * 2, num_filters)\n",
    "        self.dec1 = ConvRelu(num_filters * (2 + 1), num_filters)\n",
    "        \n",
    "        self.final = nn.Conv2d(num_filters, 1, kernel_size=1, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.relu(self.conv1(x))\n",
    "        conv2 = self.relu(self.conv2(self.pool(conv1)))\n",
    "        conv3s = self.relu(self.conv3s(self.pool(conv2)))\n",
    "        conv3 = self.relu(self.conv3(conv3s))\n",
    "        conv4s = self.relu(self.conv4s(self.pool(conv3)))\n",
    "        conv4 = self.relu(self.conv4(conv4s))\n",
    "        conv5s = self.relu(self.conv5s(self.pool(conv4)))\n",
    "        conv5 = self.relu(self.conv5(conv5s))\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        # Deconvolutions with copies of VGG11 layers of corresponding size \n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "        return F.sigmoid(self.final(dec1))\n",
    "\n",
    "\n",
    "def unet11(**kwargs):\n",
    "    model = UNet11(**kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model():\n",
    "    model = unet11()\n",
    "    model.train()\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7114b9f3da03d4688ecfdecd7c7008a0be0c8004"
   },
   "outputs": [],
   "source": [
    "def load_image(path, mask = False):\n",
    "    \"\"\"\n",
    "    Load image from a given path and pad it on the sides, so that eash side is divisible by 32 (newtwork requirement)\n",
    "    \n",
    "    if pad = True:\n",
    "        returns image as numpy.array, tuple with padding in pixels as(x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
    "    else:\n",
    "        returns image as numpy.array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Padding in needed for UNet models because they need image size to be divisible by 32 \n",
    "    if height % 32 == 0:\n",
    "        y_min_pad = 0\n",
    "        y_max_pad = 0\n",
    "    else:\n",
    "        y_pad = 32 - height % 32\n",
    "        y_min_pad = int(y_pad / 2)\n",
    "        y_max_pad = y_pad - y_min_pad\n",
    "        \n",
    "    if width % 32 == 0:\n",
    "        x_min_pad = 0\n",
    "        x_max_pad = 0\n",
    "    else:\n",
    "        x_pad = 32 - width % 32\n",
    "        x_min_pad = int(x_pad / 2)\n",
    "        x_max_pad = x_pad - x_min_pad\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad, x_min_pad, x_max_pad, cv2.BORDER_REFLECT_101)\n",
    "    if mask:\n",
    "        # Convert mask to 0 and 1 format\n",
    "        img = img[:, :, 0:1] // 255\n",
    "        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32'))\n",
    "    else:\n",
    "        img = img / 255.0\n",
    "        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "87e0c6c34c6916e43b8f4e8e1f6eb708f8049b3d"
   },
   "outputs": [],
   "source": [
    "# Adapted from vizualization kernel\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TGSSaltDataset(data.Dataset):\n",
    "    def __init__(self, root_path, file_list, is_test = False):\n",
    "        self.is_test = is_test\n",
    "        self.root_path = root_path\n",
    "        self.file_list = file_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index not in range(0, len(self.file_list)):\n",
    "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
    "        \n",
    "        file_id = self.file_list[index]\n",
    "        \n",
    "        image_folder = os.path.join(self.root_path, \"images\")\n",
    "        image_path = os.path.join(image_folder, file_id + \".png\")\n",
    "        \n",
    "        mask_folder = os.path.join(self.root_path, \"masks\")\n",
    "        mask_path = os.path.join(mask_folder, file_id + \".png\")\n",
    "        \n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return (image,)\n",
    "        else:\n",
    "            mask = load_image(mask_path, mask = True)\n",
    "            return image, mask\n",
    "\n",
    "depths_df = pd.read_csv(os.path.join(directory, 'train.csv'))\n",
    "\n",
    "train_path = os.path.join(directory, 'train')\n",
    "file_list = list(depths_df['id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "89289aeceba7a47c7478e9a7fb1232cedeed70b2"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8c6b543508d94eb6454fdbcfb4edac4d22d5eea1"
   },
   "outputs": [],
   "source": [
    "# https://github.com/leigh-plt/cs231n_hw2018/blob/master/assignment2/pytorch_tutorial.ipynb\n",
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'state_dict': model.state_dict(),\n",
    "             'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "767dae95adfbe7fefcb4cc3dd397ea8ba0e3f8d1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f2047723da4dd2b5ebfa399c9b3f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Train: 0.580, Val: 0.484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8a2996cbbe4d2586915202ed81165d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, Train: 0.458, Val: 0.415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afb95546c7d40e791f36c8c47b034a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, Train: 0.383, Val: 0.318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20467f8d7fe4e85b8a42ed42e03f526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, Train: 0.322, Val: 0.313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91da992af9af423084acda3ceba22d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, Train: 0.312, Val: 0.262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c9a6e293ff476ea88f7f914167cb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, Train: 0.274, Val: 0.266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b21d07c15ae4898bcac180f21d86965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, Train: 0.270, Val: 0.241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116e20a4791149639bc79ef9deed68ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, Train: 0.240, Val: 0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada4f3a2c37b4333987152dbb48cd00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, Train: 0.231, Val: 0.239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9b820168f14828aba68791b1d2c9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, Train: 0.218, Val: 0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831c4f2c76ef48eab558233b2bb85787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, Train: 0.199, Val: 0.204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8542bc3cefeb4dcaad4c6d0c1d903853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, Train: 0.201, Val: 0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa26e2f7ed944ffb50342a9101c2951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, Train: 0.191, Val: 0.206\n",
      "model saved to tgs-13.pth\n"
     ]
    }
   ],
   "source": [
    "file_list_val = file_list[::10]\n",
    "file_list_train = [f for f in file_list if f not in file_list_val]\n",
    "dataset = TGSSaltDataset(train_path, file_list_train)\n",
    "dataset_val = TGSSaltDataset(train_path, file_list_val)\n",
    "\n",
    "model = get_model()\n",
    "#\n",
    "epoch = 13\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for e in range(epoch):\n",
    "    train_loss = []\n",
    "    for image, mask in tqdm_notebook(data.DataLoader(dataset, batch_size = 30, shuffle = True)):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        y_pred = model(Variable(image))\n",
    "        loss = loss_fn(y_pred, Variable(mask.cuda()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.data[0])\n",
    "        \n",
    "    val_loss = []\n",
    "    for image, mask in data.DataLoader(dataset_val, batch_size = 50, shuffle = False):\n",
    "        image = image.cuda()\n",
    "        y_pred = model(Variable(image))\n",
    "\n",
    "        loss = loss_fn(y_pred, Variable(mask.cuda()))\n",
    "        val_loss.append(loss.data[0])\n",
    "\n",
    "    print(\"Epoch: %d, Train: %.3f, Val: %.3f\" % (e, np.mean(train_loss), np.mean(val_loss)))\n",
    "# save the final model\n",
    "save_checkpoint('tgs-%i.pth' % epoch, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "60392c6252c7f2628db1e4fef8ae69e29f7e753e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 names of test files: ['547bfceee8', 'de54a0fc4e', '81b84bb9c9']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "test_path = os.path.join(directory, 'test')\n",
    "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]\n",
    "print('First 3 names of test files:', test_file_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "971e75a32512f23aee3cbc629df64c8079940e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 18000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ef6cdb1ba847eca0ee28a53abc02f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test size: {len(test_file_list)}\")\n",
    "test_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)\n",
    "\n",
    "all_predictions = []\n",
    "for image in tqdm_notebook(data.DataLoader(test_dataset, batch_size = 30)):\n",
    "    image = image[0].type(torch.FloatTensor).cuda()\n",
    "    y_pred = model(Variable(image)).cpu().data.numpy()\n",
    "    all_predictions.append(y_pred)\n",
    "all_predictions_stacked = np.vstack(all_predictions)[:, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "95e82b2a7155377310f1d743dd8b077f99cba657"
   },
   "outputs": [],
   "source": [
    "height, width = 101, 101\n",
    "\n",
    "if height % 32 == 0:\n",
    "    y_min_pad = 0\n",
    "    y_max_pad = 0\n",
    "else:\n",
    "    y_pad = 32 - height % 32\n",
    "    y_min_pad = int(y_pad / 2)\n",
    "    y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "if width % 32 == 0:\n",
    "    x_min_pad = 0\n",
    "    x_max_pad = 0\n",
    "else:\n",
    "    x_pad = 32 - width % 32\n",
    "    x_min_pad = int(x_pad / 2)\n",
    "    x_max_pad = x_pad - x_min_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a0c02220ba7768ac904e2e27f449393e5182cac5"
   },
   "outputs": [],
   "source": [
    "all_predictions_stacked = all_predictions_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fc57c37629a96ac4c16dfbc18546278591716613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 101, 101)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "65d1b4f79719da90faa68bb73359a5189ea70bfd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f74494ab3d4387b1a9463991fcfc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((400, 101, 101), (400, 101, 101))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)\n",
    "\n",
    "val_predictions = []\n",
    "val_masks = []\n",
    "for image, mask in tqdm_notebook(data.DataLoader(dataset_val, batch_size = 30)):\n",
    "    image = Variable(image.type(torch.FloatTensor).cuda())\n",
    "    y_pred = model(image).cpu().data.numpy()\n",
    "    val_predictions.append(y_pred)\n",
    "    val_masks.append(mask)\n",
    "    \n",
    "val_predictions_stacked = np.vstack(val_predictions)[:, 0, :, :]\n",
    "\n",
    "val_masks_stacked = np.vstack(val_masks)[:, 0, :, :]\n",
    "val_predictions_stacked = val_predictions_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "\n",
    "val_masks_stacked = val_masks_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "val_masks_stacked.shape, val_predictions_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "dbd7cbac108805a401a445947b4cfd95721e10ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0, Metric: 0.138\n",
      "Threshold: 0.1, Metric: 0.684\n",
      "Threshold: 0.2, Metric: 0.821\n",
      "Threshold: 0.3, Metric: 0.875\n",
      "Threshold: 0.4, Metric: 0.898\n",
      "Threshold: 0.5, Metric: 0.902\n",
      "Threshold: 0.6, Metric: 0.901\n",
      "Threshold: 0.7, Metric: 0.897\n",
      "Threshold: 0.8, Metric: 0.895\n",
      "Threshold: 0.9, Metric: 0.877\n",
      "Threshold: 1.0, Metric: 0.640\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "metric_by_threshold = []\n",
    "for threshold in np.linspace(0, 1, 11):\n",
    "    val_binary_prediction = (val_predictions_stacked > threshold).astype(int)\n",
    "    \n",
    "    iou_values = []\n",
    "    for y_mask, p_mask in zip(val_masks_stacked, val_binary_prediction):\n",
    "        iou = jaccard_similarity_score(y_mask.flatten(), p_mask.flatten())\n",
    "        iou_values.append(iou)\n",
    "    iou_values = np.array(iou_values)\n",
    "    \n",
    "    accuracies = [\n",
    "        np.mean(iou_values > iou_threshold)\n",
    "        for iou_threshold in np.linspace(0.5, 0.95, 10)\n",
    "    ]\n",
    "    print('Threshold: %.1f, Metric: %.3f' % (threshold, np.mean(accuracies)))\n",
    "    metric_by_threshold.append((np.mean(accuracies), threshold))\n",
    "    \n",
    "best_metric, best_threshold = max(metric_by_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "69b3e6549ac9dac536eacd7d116d1942a61b0b50"
   },
   "outputs": [],
   "source": [
    "threshold = best_threshold\n",
    "binary_prediction = (all_predictions_stacked > threshold).astype(int)\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "all_masks = []\n",
    "for p_mask in list(binary_prediction):\n",
    "    p_mask = rle_encoding(p_mask)\n",
    "    all_masks.append(' '.join(map(str, p_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "d2d05d0ed3c54619523a55683d6e1afc22dace1f"
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame([test_file_list, all_masks]).T\n",
    "submit.columns = ['id', 'rle_mask']\n",
    "submit.to_csv('submit_baseline_torch.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
