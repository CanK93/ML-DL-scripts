{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8fc6c3e84f282d0e6f664caf9848297b6c62a16"
   },
   "source": [
    "### U-net with simple Resnet Blocks\n",
    "#### update log\n",
    "1. Correct the errors to in function iou_metric,  use \"my_iou_metric\" to moniter the training\n",
    "2. Use image size 101 x 101, no resizing\n",
    "3. Last layer dropout reduced by half\n",
    "4. replace conv2D with 2 basic resnet blocks in each level of U-net\n",
    "5.  Use faster rle_encode (> 10 times fater than RLenc ) from (https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss)\n",
    "6. set  random_state= 1234 \n",
    "\n",
    "Reference kernels:\n",
    "\n",
    "https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification\n",
    "\n",
    "https://www.kaggle.com/tgibbons/u-net-without-resizing-images\n",
    "\n",
    "https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss\n",
    "\n",
    "The results seems not reproducible,  sometimes good (best around IOU0.79 ), sometimes  not as good!\n",
    "Any suggestions to improve the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cyclelr_callback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6336d7f2864a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./utils/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcyclelr_callback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cyclelr_callback'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add, LeakyReLU\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n",
    "import sys\n",
    "sys.path.insert(0, './utils/')\n",
    "\n",
    "from cyclelr_callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 101\n",
    "im_height = 101\n",
    "im_chan = 1\n",
    "basicpath = './input/'\n",
    "path_train = basicpath + 'train/'\n",
    "path_test = basicpath + 'test/'\n",
    "\n",
    "path_train_images = path_train + 'images/'\n",
    "path_train_masks = path_train + 'masks/'\n",
    "path_test_images = path_test + 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "63c469280793719bf311d51e6ba2cdaea157d175"
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "    \n",
    "def downsample(img):# not used\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "    #return img[:img_size_ori, :img_size_ori]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "1a64babef03b9a0dbc94387a1dad54971c3e028d"
   },
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "\n",
    "train_df = pd.read_csv(\"./input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"./input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "80c3768717007fb5f087d3e01619f1a9f9a3beac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52e8d94415e4937aad301add327147e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"./input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "9f55103f7daad6f03ec874c643077fe686c31bee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1bcfd6959e40b690c7f785790e1e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"./input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "010066dd50ef4fdfa7dabe2c946fd7491f9556fd"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "51981795f0dd6b8ca7abe4db367f48313b63811e"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7fb577cdf27f365d4a912728c2a7654d0e60fac8"
   },
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = Activation('relu')(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "02967d71ee7f936254ab54acf2aa7c2e038a2b21"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 128 -> 128/2\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    #   -> 128/4\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    #  -> 128/8\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    #  -> 128/16\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "     #   -> 128/16\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = Activation('relu')(convm)\n",
    "    \n",
    "    #  -> 128/8\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = Activation('relu')(uconv4)\n",
    "    \n",
    "    #  -> 128/4\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = Activation('relu')(uconv3)\n",
    "\n",
    "    #  -> 128/2\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = Activation('relu')(uconv2)\n",
    "    \n",
    "    # 128\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = Activation('relu')(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b9d158f567c829c55139acc9e79a41761d911726"
   },
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    # Jiaxin fin that if all zeros, then, the background is treated as object\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
    "    #print(temp1)\n",
    "    intersection = temp1[0]\n",
    "    #print(\"temp2 = \",temp1[1])\n",
    "    #print(intersection.shape)\n",
    "   # print(intersection)\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    #print(np.histogram(labels, bins = true_objects))\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    #print(\"area_true = \",area_true)\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    y_pred_in = y_pred_in > 0.5 # added by sgx 20180728\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    #print(\"metric = \",metric)\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float64)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import _to_tensor\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "def dice_coef_clipped(y_true, y_pred, smooth=1.0):\n",
    "    y_true_f = K.flatten(K.round(y_true))\n",
    "    y_pred_f = K.flatten(K.round(y_pred))\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 100. * (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def bootstrapped_crossentropy(y_true, y_pred, bootstrap_type='hard', alpha=0.95):\n",
    "    target_tensor = y_true\n",
    "    prediction_tensor = y_pred\n",
    "    _epsilon = _to_tensor(K.epsilon(), prediction_tensor.dtype.base_dtype)\n",
    "    prediction_tensor = K.tf.clip_by_value(prediction_tensor, _epsilon, 1 - _epsilon)\n",
    "    prediction_tensor = K.tf.log(prediction_tensor / (1 - prediction_tensor))\n",
    "\n",
    "    if bootstrap_type == 'soft':\n",
    "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.tf.sigmoid(prediction_tensor)\n",
    "    else:\n",
    "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.tf.cast(\n",
    "            K.tf.sigmoid(prediction_tensor) > 0.5, K.tf.float32)\n",
    "    return K.mean(K.tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=bootstrap_target_tensor, logits=prediction_tensor))\n",
    "\n",
    "\n",
    "def online_bootstrapping(y_true, y_pred, pixels=512, threshold=0.5):\n",
    "    \"\"\" Implements nline Bootstrapping crossentropy loss, to train only on hard pixels,\n",
    "        see  https://arxiv.org/abs/1605.06885 Bridging Category-level and Instance-level Semantic Image Segmentation\n",
    "        The implementation is a bit different as we use binary crossentropy instead of softmax\n",
    "        SUPPORTS ONLY MINIBATCH WITH 1 ELEMENT!\n",
    "    # Arguments\n",
    "        y_true: A tensor with labels.\n",
    "        y_pred: A tensor with predicted probabilites.\n",
    "        pixels: number of hard pixels to keep\n",
    "        threshold: confidence to use, i.e. if threshold is 0.7, y_true=1, prediction=0.65 then we consider that pixel as hard\n",
    "    # Returns\n",
    "        Mean loss value\n",
    "    \"\"\"\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    difference = K.abs(y_true - y_pred)\n",
    "\n",
    "    values, indices = K.tf.nn.top_k(difference, sorted=True, k=pixels)\n",
    "    min_difference = (1 - threshold)\n",
    "    y_true = K.tf.gather(K.gather(y_true, indices), K.tf.where(values > min_difference))\n",
    "    y_pred = K.tf.gather(K.gather(y_pred, indices), K.tf.where(values > min_difference))\n",
    "\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def dice_coef_loss_border(y_true, y_pred):\n",
    "    return (1 - dice_coef_border(y_true, y_pred)) * 0.05 + 0.95 * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss_border(y_true, y_pred):\n",
    "    return bce_border(y_true, y_pred) * 0.05 + 0.95 * dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coef_border(y_true, y_pred):\n",
    "    border = get_border_mask((21, 21), y_true)\n",
    "\n",
    "    border = K.flatten(border)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.tf.gather(y_true_f, K.tf.where(border > 0.5))\n",
    "    y_pred_f = K.tf.gather(y_pred_f, K.tf.where(border > 0.5))\n",
    "\n",
    "    return dice_coef(y_true_f, y_pred_f)\n",
    "\n",
    "\n",
    "def bce_border(y_true, y_pred):\n",
    "    border = get_border_mask((21, 21), y_true)\n",
    "\n",
    "    border = K.flatten(border)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.tf.gather(y_true_f, K.tf.where(border > 0.5))\n",
    "    y_pred_f = K.tf.gather(y_pred_f, K.tf.where(border > 0.5))\n",
    "\n",
    "    return binary_crossentropy(y_true_f, y_pred_f)\n",
    "\n",
    "\n",
    "def get_border_mask(pool_size, y_true):\n",
    "    negative = 1 - y_true\n",
    "    positive = y_true\n",
    "    positive = K.pool2d(positive, pool_size=pool_size, padding=\"same\")\n",
    "    negative = K.pool2d(negative, pool_size=pool_size, padding=\"same\")\n",
    "    border = positive * negative\n",
    "    return border\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coef_loss_bce(y_true, y_pred, dice=0.5, bce=0.5, bootstrapping='hard', alpha=1.):\n",
    "    return bootstrapped_crossentropy(y_true, y_pred, bootstrapping, alpha) * bce + dice_coef_loss(y_true, y_pred) * dice\n",
    "\n",
    "\n",
    "def make_loss(loss_name):\n",
    "    if loss_name == 'crossentropy':\n",
    "        return K.binary_crossentropy\n",
    "    elif loss_name == 'crossentropy_boot':\n",
    "        def loss(y, p):\n",
    "            return bootstrapped_crossentropy(y, p, 'hard', 0.9)\n",
    "        return loss\n",
    "    elif loss_name == 'dice':\n",
    "        return dice_coef_loss\n",
    "    elif loss_name == 'bce_dice':\n",
    "        def loss(y, p):\n",
    "            return dice_coef_loss_bce(y, p, dice=0.8, bce=0.2, bootstrapping='soft', alpha=1)\n",
    "\n",
    "        return loss\n",
    "    elif loss_name == 'boot_soft':\n",
    "        def loss(y, p):\n",
    "            return dice_coef_loss_bce(y, p, dice=0.8, bce=0.2, bootstrapping='soft', alpha=0.95)\n",
    "\n",
    "        return loss\n",
    "    elif loss_name == 'boot_hard':\n",
    "        def loss(y, p):\n",
    "            return dice_coef_loss_bce(y, p, dice=0.8, bce=0.2, bootstrapping='hard', alpha=0.95)\n",
    "\n",
    "        return loss\n",
    "    elif loss_name == 'online_bootstrapping':\n",
    "        def loss(y, p):\n",
    "            return online_bootstrapping(y, p, pixels=512 * 64, threshold=0.7)\n",
    "\n",
    "        return loss\n",
    "    elif loss_name == 'dice_coef_loss_border':\n",
    "        return dice_coef_loss_border\n",
    "    elif loss_name == 'bce_dice_loss_border':\n",
    "        return bce_dice_loss_border\n",
    "    else:\n",
    "        ValueError(\"Unknown loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "072ab621d38cc93d26998f391357cb6efc791600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 128, 128, 1)\n",
      "(800, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train2 = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train2 = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train2.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "30622932f68888e895a9b8cac91810a1bb3c5e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 16) 160         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 128, 128, 16) 0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 128, 128, 16) 64          activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 128, 128, 16) 64          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 128, 128, 16) 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128, 128, 16) 64          activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128, 128, 16) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 16) 2320        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 128, 128, 16) 64          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 128, 128, 16) 0           batch_normalization_58[0][0]     \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 128, 128, 16) 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 128, 128, 16) 64          activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 128, 128, 16) 64          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128, 128, 16) 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 128, 128, 16) 64          activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 128, 128, 16) 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 16) 2320        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 128, 128, 16) 64          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 128, 128, 16) 0           batch_normalization_62[0][0]     \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 128, 128, 16) 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 16)   0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64, 64, 16)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 64, 64, 32)   4640        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 64, 64, 32)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 64, 64, 32)   128         activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 32)   128         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 64, 64, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 32)   128         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 64, 64, 32)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 32)   9248        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 64, 64, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 64, 64, 32)   0           batch_normalization_66[0][0]     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 64, 64, 32)   0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64, 64, 32)   128         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64, 64, 32)   128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 64, 64, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64, 64, 32)   128         activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 64, 64, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 32)   9248        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 64, 64, 32)   128         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 64, 64, 32)   0           batch_normalization_70[0][0]     \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 64, 64, 32)   0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 32, 32, 64)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 32, 32, 64)   256         activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 32, 32, 64)   256         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 64)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 64)   36928       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 32, 32, 64)   0           batch_normalization_74[0][0]     \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 64)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 64)   256         activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 32, 32, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 64)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 64)   256         activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 64)   36928       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 32, 32, 64)   0           batch_normalization_78[0][0]     \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 32, 64)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 64)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 128)  73856       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 128)  0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 128)  512         activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 128)  512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 128)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 128)  512         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 16, 16, 128)  0           batch_normalization_82[0][0]     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 128)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 128)  512         activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 128)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 128)  512         activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 128)  147584      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 128)  0           batch_normalization_86[0][0]     \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 128)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 128)    0           activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 8, 8, 128)    0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 256)    295168      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 256)    0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 256)    1024        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 256)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 256)    1024        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 256)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 256)    590080      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 256)    1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 256)    0           batch_normalization_90[0][0]     \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 256)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 256)    1024        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 256)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 256)    1024        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 256)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 256)    590080      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 256)    0           batch_normalization_94[0][0]     \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 256)    0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 128)  295040      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 256)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 128)  295040      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 128)  0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 16, 16, 128)  512         activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 16, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 16, 128)  512         activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 128)  147584      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 16, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 16, 16, 128)  0           batch_normalization_98[0][0]     \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 128)  0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 128)  512         activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 128)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 128)  512         activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 128)  147584      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 128)  512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 128)  0           batch_normalization_102[0][0]    \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 128)  0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 64)   73792       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_6[0][0]         \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 128)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 64)   73792       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 32, 32, 64)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 32, 64)   256         activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 32, 32, 64)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 64)   256         activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 32, 32, 64)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 64)   36928       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 32, 32, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 32, 32, 64)   0           batch_normalization_106[0][0]    \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 64)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 32, 32, 64)   256         activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, 32, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 64)   256         activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 32, 32, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 64)   36928       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 32, 32, 64)   0           batch_normalization_110[0][0]    \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 32, 32, 64)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 32)   18464       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_7[0][0]         \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64, 64, 64)   0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 64, 64, 32)   18464       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 64, 64, 32)   0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 64, 64, 32)   128         activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 64, 64, 32)   128         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 64, 64, 32)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 64, 64, 32)   128         activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 64, 64, 32)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 64, 64, 32)   9248        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 64, 64, 32)   128         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 32)   0           batch_normalization_114[0][0]    \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 64, 64, 32)   0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 64, 64, 32)   128         activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 64, 64, 32)   128         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 64, 64, 32)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 64, 64, 32)   128         activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 64, 64, 32)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 64, 64, 32)   9248        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 64, 64, 32)   128         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 32)   0           batch_normalization_118[0][0]    \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 64, 64, 32)   0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 128, 128, 16) 4624        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 128, 128, 32) 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 16) 4624        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 128, 128, 16) 0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 128, 128, 16) 64          activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 128, 128, 16) 64          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 128, 128, 16) 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 128, 128, 16) 64          activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 128, 128, 16) 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 128, 128, 16) 2320        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 128, 128, 16) 64          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 128, 128, 16) 0           batch_normalization_122[0][0]    \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 128, 128, 16) 0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 128, 128, 16) 64          activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 128, 128, 16) 64          conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 128, 128, 16) 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 128, 128, 16) 64          activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 128, 128, 16) 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 128, 128, 16) 2320        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 128, 128, 16) 64          conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 128, 128, 16) 0           batch_normalization_126[0][0]    \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 128, 128, 16) 0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 128, 128, 16) 0           activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 128, 128, 1)  17          dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,128,689\n",
      "Trainable params: 5,116,913\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "# input_layer2 = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "# del model\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[my_iou_metric])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "41699081be465c14e193ffad4fd00bd56840f156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      " - 67s - loss: 0.4553 - my_iou_metric: 0.1038 - val_loss: 0.4638 - val_my_iou_metric: 0.1141\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.11413, saving model to ./unet_best1.model\n",
      "Epoch 2/200\n",
      " - 56s - loss: 0.3151 - my_iou_metric: 0.2564 - val_loss: 0.5788 - val_my_iou_metric: 0.2230\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.11413 to 0.22300, saving model to ./unet_best1.model\n",
      "Epoch 3/200\n",
      " - 58s - loss: 0.2668 - my_iou_metric: 0.4053 - val_loss: 0.4495 - val_my_iou_metric: 0.2657\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.22300 to 0.26575, saving model to ./unet_best1.model\n",
      "Epoch 4/200\n",
      " - 59s - loss: 0.2650 - my_iou_metric: 0.4650 - val_loss: 0.3026 - val_my_iou_metric: 0.4848\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.26575 to 0.48475, saving model to ./unet_best1.model\n",
      "Epoch 5/200\n",
      " - 59s - loss: 0.2522 - my_iou_metric: 0.4889 - val_loss: 0.2738 - val_my_iou_metric: 0.5985\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.48475 to 0.59850, saving model to ./unet_best1.model\n",
      "Epoch 6/200\n",
      " - 56s - loss: 0.2461 - my_iou_metric: 0.5167 - val_loss: 0.3482 - val_my_iou_metric: 0.4636\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 7/200\n",
      " - 55s - loss: 0.2355 - my_iou_metric: 0.5223 - val_loss: 0.2975 - val_my_iou_metric: 0.5672\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 8/200\n",
      " - 56s - loss: 0.2396 - my_iou_metric: 0.5279 - val_loss: 0.5493 - val_my_iou_metric: 0.0644\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 9/200\n",
      " - 55s - loss: 0.2446 - my_iou_metric: 0.5228 - val_loss: 0.2758 - val_my_iou_metric: 0.5555\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 10/200\n",
      " - 55s - loss: 0.2322 - my_iou_metric: 0.5445 - val_loss: 0.3324 - val_my_iou_metric: 0.4896\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 11/200\n",
      " - 55s - loss: 0.2203 - my_iou_metric: 0.5619 - val_loss: 0.4435 - val_my_iou_metric: 0.4064\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 12/200\n",
      " - 55s - loss: 0.2072 - my_iou_metric: 0.5666 - val_loss: 0.3854 - val_my_iou_metric: 0.4574\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 13/200\n",
      " - 55s - loss: 0.1900 - my_iou_metric: 0.6035 - val_loss: 0.2662 - val_my_iou_metric: 0.5929\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.59850\n",
      "Epoch 14/200\n",
      " - 56s - loss: 0.1819 - my_iou_metric: 0.6119 - val_loss: 0.1717 - val_my_iou_metric: 0.6536\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.59850 to 0.65363, saving model to ./unet_best1.model\n",
      "Epoch 15/200\n",
      " - 56s - loss: 0.1780 - my_iou_metric: 0.6353 - val_loss: 0.3408 - val_my_iou_metric: 0.4946\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.65363\n",
      "Epoch 16/200\n",
      " - 55s - loss: 0.2300 - my_iou_metric: 0.5289 - val_loss: 0.2401 - val_my_iou_metric: 0.5851\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.65363\n",
      "Epoch 17/200\n",
      " - 55s - loss: 0.1880 - my_iou_metric: 0.6077 - val_loss: 0.1683 - val_my_iou_metric: 0.6820\n",
      "\n",
      "Epoch 00017: val_my_iou_metric improved from 0.65363 to 0.68200, saving model to ./unet_best1.model\n",
      "Epoch 18/200\n",
      " - 55s - loss: 0.1732 - my_iou_metric: 0.6355 - val_loss: 0.1819 - val_my_iou_metric: 0.6671\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.68200\n",
      "Epoch 19/200\n",
      " - 55s - loss: 0.1598 - my_iou_metric: 0.6673 - val_loss: 0.1586 - val_my_iou_metric: 0.7021\n",
      "\n",
      "Epoch 00019: val_my_iou_metric improved from 0.68200 to 0.70213, saving model to ./unet_best1.model\n",
      "Epoch 20/200\n",
      " - 55s - loss: 0.1511 - my_iou_metric: 0.6852 - val_loss: 0.1531 - val_my_iou_metric: 0.6878\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 21/200\n",
      " - 55s - loss: 0.1476 - my_iou_metric: 0.6792 - val_loss: 0.1593 - val_my_iou_metric: 0.6871\n",
      "\n",
      "Epoch 00021: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 22/200\n",
      " - 55s - loss: 0.1483 - my_iou_metric: 0.6800 - val_loss: 0.1558 - val_my_iou_metric: 0.6867\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 23/200\n",
      " - 56s - loss: 0.1514 - my_iou_metric: 0.6798 - val_loss: 0.1750 - val_my_iou_metric: 0.6314\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 24/200\n",
      " - 55s - loss: 0.1486 - my_iou_metric: 0.6846 - val_loss: 0.1841 - val_my_iou_metric: 0.6694\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 25/200\n",
      " - 55s - loss: 0.1516 - my_iou_metric: 0.6793 - val_loss: 0.1793 - val_my_iou_metric: 0.6785\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve from 0.70213\n",
      "Epoch 26/200\n",
      " - 57s - loss: 0.1538 - my_iou_metric: 0.6758 - val_loss: 0.1582 - val_my_iou_metric: 0.7105\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.70213 to 0.71050, saving model to ./unet_best1.model\n",
      "Epoch 27/200\n",
      " - 57s - loss: 0.1560 - my_iou_metric: 0.6756 - val_loss: 0.2016 - val_my_iou_metric: 0.6531\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 28/200\n",
      " - 56s - loss: 0.1618 - my_iou_metric: 0.6634 - val_loss: 0.1613 - val_my_iou_metric: 0.6819\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 29/200\n",
      " - 58s - loss: 0.1598 - my_iou_metric: 0.6620 - val_loss: 0.1766 - val_my_iou_metric: 0.6721\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 30/200\n",
      " - 56s - loss: 0.1663 - my_iou_metric: 0.6611 - val_loss: 0.1823 - val_my_iou_metric: 0.7003\n",
      "\n",
      "Epoch 00030: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 31/200\n",
      " - 57s - loss: 0.1638 - my_iou_metric: 0.6713 - val_loss: 0.1776 - val_my_iou_metric: 0.7011\n",
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 32/200\n",
      " - 56s - loss: 0.1555 - my_iou_metric: 0.6704 - val_loss: 0.1733 - val_my_iou_metric: 0.6665\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 33/200\n",
      " - 57s - loss: 0.1561 - my_iou_metric: 0.6806 - val_loss: 0.1594 - val_my_iou_metric: 0.7070\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 34/200\n",
      " - 57s - loss: 0.1468 - my_iou_metric: 0.6890 - val_loss: 0.1729 - val_my_iou_metric: 0.6787\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.71050\n",
      "Epoch 35/200\n",
      " - 57s - loss: 0.1422 - my_iou_metric: 0.7037 - val_loss: 0.1471 - val_my_iou_metric: 0.7133\n",
      "\n",
      "Epoch 00035: val_my_iou_metric improved from 0.71050 to 0.71325, saving model to ./unet_best1.model\n",
      "Epoch 36/200\n",
      " - 56s - loss: 0.1368 - my_iou_metric: 0.7086 - val_loss: 0.1600 - val_my_iou_metric: 0.7247\n",
      "\n",
      "Epoch 00036: val_my_iou_metric improved from 0.71325 to 0.72475, saving model to ./unet_best1.model\n",
      "Epoch 37/200\n",
      " - 55s - loss: 0.1311 - my_iou_metric: 0.7198 - val_loss: 0.1695 - val_my_iou_metric: 0.6849\n",
      "\n",
      "Epoch 00037: val_my_iou_metric did not improve from 0.72475\n",
      "Epoch 38/200\n",
      " - 55s - loss: 0.1305 - my_iou_metric: 0.7155 - val_loss: 0.1541 - val_my_iou_metric: 0.7229\n",
      "\n",
      "Epoch 00038: val_my_iou_metric did not improve from 0.72475\n",
      "Epoch 39/200\n",
      " - 56s - loss: 0.1225 - my_iou_metric: 0.7304 - val_loss: 0.1523 - val_my_iou_metric: 0.7249\n",
      "\n",
      "Epoch 00039: val_my_iou_metric improved from 0.72475 to 0.72487, saving model to ./unet_best1.model\n",
      "Epoch 40/200\n",
      " - 57s - loss: 0.1194 - my_iou_metric: 0.7389 - val_loss: 0.1450 - val_my_iou_metric: 0.7395\n",
      "\n",
      "Epoch 00040: val_my_iou_metric improved from 0.72487 to 0.73950, saving model to ./unet_best1.model\n",
      "Epoch 41/200\n",
      " - 56s - loss: 0.1162 - my_iou_metric: 0.7415 - val_loss: 0.1453 - val_my_iou_metric: 0.7328\n",
      "\n",
      "Epoch 00041: val_my_iou_metric did not improve from 0.73950\n",
      "Epoch 42/200\n",
      " - 57s - loss: 0.1167 - my_iou_metric: 0.7360 - val_loss: 0.1442 - val_my_iou_metric: 0.7285\n",
      "\n",
      "Epoch 00042: val_my_iou_metric did not improve from 0.73950\n",
      "Epoch 43/200\n",
      " - 56s - loss: 0.1171 - my_iou_metric: 0.7360 - val_loss: 0.1477 - val_my_iou_metric: 0.7283\n",
      "\n",
      "Epoch 00043: val_my_iou_metric did not improve from 0.73950\n",
      "Epoch 44/200\n",
      " - 57s - loss: 0.1186 - my_iou_metric: 0.7367 - val_loss: 0.1463 - val_my_iou_metric: 0.7558\n",
      "\n",
      "Epoch 00044: val_my_iou_metric improved from 0.73950 to 0.75575, saving model to ./unet_best1.model\n",
      "Epoch 45/200\n",
      " - 56s - loss: 0.1205 - my_iou_metric: 0.7334 - val_loss: 0.1361 - val_my_iou_metric: 0.7437\n",
      "\n",
      "Epoch 00045: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 46/200\n",
      " - 56s - loss: 0.1226 - my_iou_metric: 0.7319 - val_loss: 0.1498 - val_my_iou_metric: 0.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 47/200\n",
      " - 55s - loss: 0.1201 - my_iou_metric: 0.7315 - val_loss: 0.1510 - val_my_iou_metric: 0.7422\n",
      "\n",
      "Epoch 00047: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 48/200\n",
      " - 56s - loss: 0.1233 - my_iou_metric: 0.7277 - val_loss: 0.1702 - val_my_iou_metric: 0.7324\n",
      "\n",
      "Epoch 00048: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 49/200\n",
      " - 56s - loss: 0.1242 - my_iou_metric: 0.7313 - val_loss: 0.1584 - val_my_iou_metric: 0.7260\n",
      "\n",
      "Epoch 00049: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 50/200\n",
      " - 56s - loss: 0.1275 - my_iou_metric: 0.7284 - val_loss: 0.1959 - val_my_iou_metric: 0.6964\n",
      "\n",
      "Epoch 00050: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 51/200\n",
      " - 57s - loss: 0.1286 - my_iou_metric: 0.7195 - val_loss: 0.1681 - val_my_iou_metric: 0.7153\n",
      "\n",
      "Epoch 00051: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 52/200\n",
      " - 56s - loss: 0.1267 - my_iou_metric: 0.7247 - val_loss: 0.1579 - val_my_iou_metric: 0.7277\n",
      "\n",
      "Epoch 00052: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 53/200\n",
      " - 56s - loss: 0.1272 - my_iou_metric: 0.7288 - val_loss: 0.1458 - val_my_iou_metric: 0.7231\n",
      "\n",
      "Epoch 00053: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 54/200\n",
      " - 55s - loss: 0.1190 - my_iou_metric: 0.7357 - val_loss: 0.1578 - val_my_iou_metric: 0.7215\n",
      "\n",
      "Epoch 00054: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 55/200\n",
      " - 56s - loss: 0.1166 - my_iou_metric: 0.7414 - val_loss: 0.1524 - val_my_iou_metric: 0.7318\n",
      "\n",
      "Epoch 00055: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 56/200\n",
      " - 56s - loss: 0.1118 - my_iou_metric: 0.7465 - val_loss: 0.1386 - val_my_iou_metric: 0.7501\n",
      "\n",
      "Epoch 00056: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 57/200\n",
      " - 56s - loss: 0.1069 - my_iou_metric: 0.7519 - val_loss: 0.1369 - val_my_iou_metric: 0.7538\n",
      "\n",
      "Epoch 00057: val_my_iou_metric did not improve from 0.75575\n",
      "Epoch 58/200\n",
      " - 56s - loss: 0.1055 - my_iou_metric: 0.7515 - val_loss: 0.1368 - val_my_iou_metric: 0.7601\n",
      "\n",
      "Epoch 00058: val_my_iou_metric improved from 0.75575 to 0.76013, saving model to ./unet_best1.model\n",
      "Epoch 59/200\n",
      " - 56s - loss: 0.1029 - my_iou_metric: 0.7592 - val_loss: 0.1391 - val_my_iou_metric: 0.7506\n",
      "\n",
      "Epoch 00059: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 60/200\n",
      " - 57s - loss: 0.0999 - my_iou_metric: 0.7604 - val_loss: 0.1395 - val_my_iou_metric: 0.7537\n",
      "\n",
      "Epoch 00060: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 61/200\n",
      " - 58s - loss: 0.0995 - my_iou_metric: 0.7626 - val_loss: 0.1416 - val_my_iou_metric: 0.7546\n",
      "\n",
      "Epoch 00061: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 62/200\n",
      " - 57s - loss: 0.0991 - my_iou_metric: 0.7642 - val_loss: 0.1411 - val_my_iou_metric: 0.7567\n",
      "\n",
      "Epoch 00062: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 63/200\n",
      " - 57s - loss: 0.0971 - my_iou_metric: 0.7673 - val_loss: 0.1389 - val_my_iou_metric: 0.7584\n",
      "\n",
      "Epoch 00063: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 64/200\n",
      " - 57s - loss: 0.1008 - my_iou_metric: 0.7596 - val_loss: 0.1357 - val_my_iou_metric: 0.7482\n",
      "\n",
      "Epoch 00064: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 65/200\n",
      " - 57s - loss: 0.1005 - my_iou_metric: 0.7633 - val_loss: 0.1448 - val_my_iou_metric: 0.7551\n",
      "\n",
      "Epoch 00065: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 66/200\n",
      " - 57s - loss: 0.1012 - my_iou_metric: 0.7602 - val_loss: 0.1442 - val_my_iou_metric: 0.7564\n",
      "\n",
      "Epoch 00066: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 67/200\n",
      " - 59s - loss: 0.1035 - my_iou_metric: 0.7595 - val_loss: 0.1298 - val_my_iou_metric: 0.7486\n",
      "\n",
      "Epoch 00067: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 68/200\n",
      " - 59s - loss: 0.1051 - my_iou_metric: 0.7569 - val_loss: 0.1473 - val_my_iou_metric: 0.7486\n",
      "\n",
      "Epoch 00068: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 69/200\n",
      " - 57s - loss: 0.1060 - my_iou_metric: 0.7587 - val_loss: 0.1418 - val_my_iou_metric: 0.7469\n",
      "\n",
      "Epoch 00069: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 70/200\n",
      " - 56s - loss: 0.1041 - my_iou_metric: 0.7605 - val_loss: 0.1494 - val_my_iou_metric: 0.7565\n",
      "\n",
      "Epoch 00070: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 71/200\n",
      " - 57s - loss: 0.1006 - my_iou_metric: 0.7567 - val_loss: 0.1489 - val_my_iou_metric: 0.7534\n",
      "\n",
      "Epoch 00071: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 72/200\n",
      " - 57s - loss: 0.1036 - my_iou_metric: 0.7586 - val_loss: 0.1355 - val_my_iou_metric: 0.7503\n",
      "\n",
      "Epoch 00072: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 73/200\n",
      " - 57s - loss: 0.0999 - my_iou_metric: 0.7650 - val_loss: 0.1454 - val_my_iou_metric: 0.7439\n",
      "\n",
      "Epoch 00073: val_my_iou_metric did not improve from 0.76013\n",
      "Epoch 74/200\n",
      " - 57s - loss: 0.1017 - my_iou_metric: 0.7582 - val_loss: 0.1271 - val_my_iou_metric: 0.7610\n",
      "\n",
      "Epoch 00074: val_my_iou_metric improved from 0.76013 to 0.76100, saving model to ./unet_best1.model\n",
      "Epoch 75/200\n",
      " - 57s - loss: 0.0974 - my_iou_metric: 0.7651 - val_loss: 0.1359 - val_my_iou_metric: 0.7566\n",
      "\n",
      "Epoch 00075: val_my_iou_metric did not improve from 0.76100\n",
      "Epoch 76/200\n",
      " - 56s - loss: 0.0985 - my_iou_metric: 0.7729 - val_loss: 0.1425 - val_my_iou_metric: 0.7582\n",
      "\n",
      "Epoch 00076: val_my_iou_metric did not improve from 0.76100\n",
      "Epoch 77/200\n",
      " - 57s - loss: 0.0942 - my_iou_metric: 0.7692 - val_loss: 0.1387 - val_my_iou_metric: 0.7617\n",
      "\n",
      "Epoch 00077: val_my_iou_metric improved from 0.76100 to 0.76175, saving model to ./unet_best1.model\n",
      "Epoch 78/200\n",
      " - 57s - loss: 0.0932 - my_iou_metric: 0.7731 - val_loss: 0.1408 - val_my_iou_metric: 0.7572\n",
      "\n",
      "Epoch 00078: val_my_iou_metric did not improve from 0.76175\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-80d8d718d0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclr_triangular\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clr_triangular = CyclicLR(mode='triangular2', base_lr=0.0001, max_lr=0.006) \n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "#https://github.com/bckenstler/CLR\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train2, y_train2,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, clr_triangular], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "81aba20e2904bcab1c3ac601f28a880f856e491b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-829c5e05b45e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_iou_metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_my_iou_metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['my_iou_metric'][1:])\n",
    "plt.plot(history.history['val_my_iou_metric'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "347c6567c95430f28ec51b94f42603e37a4056db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b9dd46189cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "a081f8f61a713457c8c8f3979a78f75541875456"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./keras 741lb.model\",custom_objects={'my_iou_metric': my_iou_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5da2648534e6f8a4d2fbd8995cf9e6a1c9c0d227"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test1 = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    preds_avg = (preds_test1 +preds_test2)/2\n",
    "    return preds_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "b7a061700364ea17735f953d6bd3c835bc3dc630"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,128)\n",
    "preds_valid2 = np.array([downsample(x) for x in preds_valid])\n",
    "\n",
    "y_valid2 = np.array([downsample(x) for x in y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "91b1be75d7e8ff74db956c8c846c47ed7576ecb2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894d0986db32431d9e6f8044f225e65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Scoring for last model\n",
    "thresholds = np.linspace(0.3, 0.7, 31)\n",
    "ious = np.array([iou_metric_batch(y_valid2, np.int32(preds_valid2 > threshold)) for threshold in tqdm_notebook(thresholds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "1beb285910aa6532d7a69a70afa6a9671e6d347d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f62c2092908>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "2c4852ecf2c504a4ce30e975f5e36b534c2111e6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59089e7f032488c9d872f6770776c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([upsample(np.array(load_img(\"./input/test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "ce8185fa64aafbe42ebde98aba984b4f22b0050e"
   },
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_test.dump('7997.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test2 = np.load(\"7997.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 101, 101)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = preds_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0415a39870204a41bce6d40cb08bb589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, idx in enumerate(tqdm_notebook(test_df.index.values)):\n",
    "    temp[i] = downsample(preds_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_avg = ((temp)*0.3 + preds_test2*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(img):\n",
    "    if img.sum() < 77:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "7ccac81a492b9caaff4a25401165e145cf2c6f8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9421c6766a0244bda3d3b38be28de2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usedtime = 13.025543212890625 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(filter_image(preds_avg[i] > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "for idx, pred in tqdm(zip(ids, predictions)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "770d7d596656f4f1ad17a6063ad662ac80e11b24"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('./output/resnet batch norm cycle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "031bc2ef4548059939fae54c06f24f68e0ad3330"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
